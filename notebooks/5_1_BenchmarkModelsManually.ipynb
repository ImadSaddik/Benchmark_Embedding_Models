{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be6c22b",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36b3353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 embedding files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_dir = \"../data/embeddings/\"\n",
    "all_files = []\n",
    "for file in os.listdir(embeddings_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        all_files.append(os.path.join(embeddings_dir, file))\n",
    "\n",
    "print(f\"Found {len(all_files)} embedding files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f3990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks    : 120\n",
      "Number of questions : 1209\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "chunks = []\n",
    "questions = []\n",
    "chunk_id_counter = 0\n",
    "\n",
    "for file_path in all_files:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    file_chunks = data[\"chunks\"]\n",
    "    file_questions = data[\"question_answer_pairs\"]\n",
    "\n",
    "    old_to_new_id_map = {}\n",
    "\n",
    "    # Update chunk IDs and add to the main list\n",
    "    for chunk in file_chunks:\n",
    "        old_id = chunk[\"id\"]\n",
    "        new_id = chunk_id_counter\n",
    "        old_to_new_id_map[old_id] = new_id\n",
    "        chunk[\"id\"] = new_id\n",
    "        chunks.append(chunk)\n",
    "        chunk_id_counter += 1\n",
    "\n",
    "    # Update chunk_id in questions and add to the main list\n",
    "    for question in file_questions:\n",
    "        old_chunk_id = question[\"chunk_id\"]\n",
    "        if old_chunk_id in old_to_new_id_map:\n",
    "            question[\"chunk_id\"] = old_to_new_id_map[old_chunk_id]\n",
    "            questions.append(question)\n",
    "\n",
    "print(f\"Number of chunks    : {len(chunks)}\")\n",
    "print(f\"Number of questions : {len(questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f61df1",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "There are several metrics commonly used to benchmark embedding models. In this notebook, you will use the following metrics:\n",
    "\n",
    "- **Mean Reciprocal Rank (MRR)**\n",
    "- **Recall@K**\n",
    "- **Normalized Discounted Cumulative Gain (NDCG)**\n",
    "\n",
    "For more details and additional metrics, see the [ranx metrics documentation](https://amenra.github.io/ranx/metrics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3959df",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank (MRR)\n",
    "\n",
    "MRR measures how quickly the first relevant result appears in the ranked list. The equation is:\n",
    "\n",
    "$$\n",
    "\\text{MRR} = \\frac{1}{\\text{rank}}\n",
    "$$\n",
    "\n",
    "where **rank** is the position of the first relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f5082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculate_mrr(rank: int | None) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "    return 1.0 / rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dca184",
   "metadata": {},
   "source": [
    "### Recall@K\n",
    "\n",
    "Recall@K indicates whether the relevant document appears within the top-$K$ results.  \n",
    "For datasets with one relevant document ($R=1$):\n",
    "\n",
    "$$\n",
    "\\text{Recall@K} = \\frac{r}{R}\n",
    "$$\n",
    "\n",
    "where $r$ is 1 if the relevant document is in the top-$K$, otherwise 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ff37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(rank: int | None, k: int) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "    return 1.0 if rank <= k else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72b463",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG@K)\n",
    "\n",
    "N[DCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)@K evaluates ranking quality, considering the position of the relevant document.  \n",
    "For a single relevant document:\n",
    "\n",
    "$$\n",
    "\\text{DCG@K} = \n",
    "\\begin{cases}\n",
    "\\frac{1}{\\log_2(\\text{rank} + 1)}, & \\text{if rank} \\leq K \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{IDCG@K} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}} = \\text{DCG@K}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f160d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_k(rank: int | None, k: int) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "\n",
    "    if rank <= k:\n",
    "        return 1.0 / math.log2(rank + 1)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f464e9d",
   "metadata": {},
   "source": [
    "## Prepare data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2cd29",
   "metadata": {},
   "source": [
    "Get the list of embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dda7fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text-embedding-3-small', 'text-embedding-3-large', 'all-minilm-l6-v2', 'gemini-embedding-001', 'qwen3-embedding-0.6b', 'qwen3-embedding-8b', 'qwen3-embedding-4b']\n"
     ]
    }
   ],
   "source": [
    "models_to_benchmark = list(chunks[0][\"embeddings\"].keys())\n",
    "print(models_to_benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc4a18",
   "metadata": {},
   "source": [
    "Create a mapping from each question to its correct chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9af601c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 1,\n",
       " 14: 1,\n",
       " 15: 1,\n",
       " 16: 1,\n",
       " 17: 1,\n",
       " 18: 1,\n",
       " 19: 2,\n",
       " 20: 2,\n",
       " 21: 2,\n",
       " 22: 2,\n",
       " 23: 2,\n",
       " 24: 2,\n",
       " 25: 3,\n",
       " 26: 3,\n",
       " 27: 3,\n",
       " 28: 3,\n",
       " 29: 3,\n",
       " 30: 3,\n",
       " 31: 3,\n",
       " 32: 3,\n",
       " 33: 4,\n",
       " 34: 4,\n",
       " 35: 4,\n",
       " 36: 4,\n",
       " 37: 4,\n",
       " 38: 4,\n",
       " 39: 4,\n",
       " 40: 5,\n",
       " 41: 5,\n",
       " 42: 5,\n",
       " 43: 5,\n",
       " 44: 5,\n",
       " 45: 5,\n",
       " 46: 5,\n",
       " 47: 5,\n",
       " 48: 6,\n",
       " 49: 6,\n",
       " 50: 6,\n",
       " 51: 6,\n",
       " 52: 6,\n",
       " 53: 6,\n",
       " 54: 6,\n",
       " 55: 6,\n",
       " 56: 7,\n",
       " 57: 7,\n",
       " 58: 7,\n",
       " 59: 7,\n",
       " 60: 7,\n",
       " 61: 7,\n",
       " 62: 7,\n",
       " 63: 7,\n",
       " 64: 8,\n",
       " 65: 8,\n",
       " 66: 8,\n",
       " 67: 8,\n",
       " 68: 8,\n",
       " 69: 8,\n",
       " 70: 8,\n",
       " 71: 8,\n",
       " 72: 8,\n",
       " 73: 8,\n",
       " 74: 9,\n",
       " 75: 9,\n",
       " 76: 9,\n",
       " 77: 9,\n",
       " 78: 9,\n",
       " 79: 9,\n",
       " 80: 9,\n",
       " 81: 9,\n",
       " 82: 9,\n",
       " 83: 9,\n",
       " 84: 9,\n",
       " 85: 9,\n",
       " 86: 9,\n",
       " 87: 9,\n",
       " 88: 9,\n",
       " 89: 9,\n",
       " 90: 9,\n",
       " 91: 9,\n",
       " 92: 9,\n",
       " 93: 9,\n",
       " 94: 10,\n",
       " 95: 10,\n",
       " 96: 10,\n",
       " 97: 10,\n",
       " 98: 10,\n",
       " 99: 10,\n",
       " 100: 10,\n",
       " 101: 10,\n",
       " 102: 10,\n",
       " 103: 10,\n",
       " 104: 11,\n",
       " 105: 11,\n",
       " 106: 11,\n",
       " 107: 11,\n",
       " 108: 11,\n",
       " 109: 11,\n",
       " 110: 11,\n",
       " 111: 11,\n",
       " 112: 11,\n",
       " 113: 11,\n",
       " 114: 12,\n",
       " 115: 12,\n",
       " 116: 12,\n",
       " 117: 12,\n",
       " 118: 12,\n",
       " 119: 12,\n",
       " 120: 12,\n",
       " 121: 13,\n",
       " 122: 13,\n",
       " 123: 13,\n",
       " 124: 13,\n",
       " 125: 13,\n",
       " 126: 13,\n",
       " 127: 13,\n",
       " 128: 13,\n",
       " 129: 13,\n",
       " 130: 13,\n",
       " 131: 13,\n",
       " 132: 13,\n",
       " 133: 13,\n",
       " 134: 13,\n",
       " 135: 14,\n",
       " 136: 14,\n",
       " 137: 14,\n",
       " 138: 14,\n",
       " 139: 14,\n",
       " 140: 14,\n",
       " 141: 14,\n",
       " 142: 14,\n",
       " 143: 15,\n",
       " 144: 15,\n",
       " 145: 15,\n",
       " 146: 15,\n",
       " 147: 15,\n",
       " 148: 15,\n",
       " 149: 15,\n",
       " 150: 15,\n",
       " 151: 16,\n",
       " 152: 16,\n",
       " 153: 16,\n",
       " 154: 16,\n",
       " 155: 16,\n",
       " 156: 16,\n",
       " 157: 16,\n",
       " 158: 16,\n",
       " 159: 17,\n",
       " 160: 17,\n",
       " 161: 17,\n",
       " 162: 17,\n",
       " 163: 17,\n",
       " 164: 17,\n",
       " 165: 17,\n",
       " 166: 18,\n",
       " 167: 18,\n",
       " 168: 18,\n",
       " 169: 18,\n",
       " 170: 18,\n",
       " 171: 18,\n",
       " 172: 18,\n",
       " 173: 18,\n",
       " 174: 18,\n",
       " 175: 19,\n",
       " 176: 19,\n",
       " 177: 19,\n",
       " 178: 19,\n",
       " 179: 19,\n",
       " 180: 19,\n",
       " 181: 19,\n",
       " 182: 19,\n",
       " 183: 20,\n",
       " 184: 20,\n",
       " 185: 20,\n",
       " 186: 20,\n",
       " 187: 20,\n",
       " 188: 20,\n",
       " 189: 20,\n",
       " 190: 20,\n",
       " 191: 20,\n",
       " 192: 20,\n",
       " 193: 20,\n",
       " 194: 20,\n",
       " 195: 20,\n",
       " 196: 20,\n",
       " 197: 20,\n",
       " 198: 20,\n",
       " 199: 20,\n",
       " 200: 21,\n",
       " 201: 21,\n",
       " 202: 21,\n",
       " 203: 21,\n",
       " 204: 21,\n",
       " 205: 21,\n",
       " 206: 21,\n",
       " 207: 21,\n",
       " 208: 22,\n",
       " 209: 22,\n",
       " 210: 22,\n",
       " 211: 22,\n",
       " 212: 22,\n",
       " 213: 22,\n",
       " 214: 22,\n",
       " 215: 23,\n",
       " 216: 23,\n",
       " 217: 23,\n",
       " 218: 23,\n",
       " 219: 23,\n",
       " 220: 23,\n",
       " 221: 23,\n",
       " 222: 24,\n",
       " 223: 24,\n",
       " 224: 24,\n",
       " 225: 24,\n",
       " 226: 24,\n",
       " 227: 24,\n",
       " 228: 24,\n",
       " 229: 25,\n",
       " 230: 25,\n",
       " 231: 25,\n",
       " 232: 25,\n",
       " 233: 25,\n",
       " 234: 25,\n",
       " 235: 25,\n",
       " 236: 25,\n",
       " 237: 25,\n",
       " 238: 26,\n",
       " 239: 26,\n",
       " 240: 26,\n",
       " 241: 26,\n",
       " 242: 26,\n",
       " 243: 26,\n",
       " 244: 26,\n",
       " 245: 26,\n",
       " 246: 26,\n",
       " 247: 27,\n",
       " 248: 27,\n",
       " 249: 27,\n",
       " 250: 27,\n",
       " 251: 27,\n",
       " 252: 27,\n",
       " 253: 27,\n",
       " 254: 27,\n",
       " 255: 27,\n",
       " 256: 27,\n",
       " 257: 27,\n",
       " 258: 28,\n",
       " 259: 28,\n",
       " 260: 28,\n",
       " 261: 28,\n",
       " 262: 28,\n",
       " 263: 28,\n",
       " 264: 28,\n",
       " 265: 28,\n",
       " 266: 29,\n",
       " 267: 29,\n",
       " 268: 29,\n",
       " 269: 29,\n",
       " 270: 29,\n",
       " 271: 29,\n",
       " 272: 29,\n",
       " 273: 29,\n",
       " 274: 29,\n",
       " 275: 29,\n",
       " 276: 29,\n",
       " 277: 29,\n",
       " 278: 29,\n",
       " 279: 30,\n",
       " 280: 30,\n",
       " 281: 30,\n",
       " 282: 30,\n",
       " 283: 30,\n",
       " 284: 30,\n",
       " 285: 30,\n",
       " 286: 30,\n",
       " 287: 30,\n",
       " 288: 31,\n",
       " 289: 31,\n",
       " 290: 31,\n",
       " 291: 31,\n",
       " 292: 31,\n",
       " 293: 31,\n",
       " 294: 31,\n",
       " 295: 31,\n",
       " 296: 31,\n",
       " 297: 31,\n",
       " 298: 31,\n",
       " 299: 31,\n",
       " 300: 31,\n",
       " 301: 31,\n",
       " 302: 31,\n",
       " 303: 31,\n",
       " 304: 32,\n",
       " 305: 32,\n",
       " 306: 32,\n",
       " 307: 32,\n",
       " 308: 32,\n",
       " 309: 32,\n",
       " 310: 32,\n",
       " 311: 32,\n",
       " 312: 32,\n",
       " 313: 32,\n",
       " 314: 32,\n",
       " 315: 33,\n",
       " 316: 33,\n",
       " 317: 33,\n",
       " 318: 33,\n",
       " 319: 33,\n",
       " 320: 33,\n",
       " 321: 33,\n",
       " 322: 33,\n",
       " 323: 33,\n",
       " 324: 34,\n",
       " 325: 34,\n",
       " 326: 34,\n",
       " 327: 34,\n",
       " 328: 34,\n",
       " 329: 34,\n",
       " 330: 34,\n",
       " 331: 34,\n",
       " 332: 34,\n",
       " 333: 34,\n",
       " 334: 34,\n",
       " 335: 34,\n",
       " 336: 34,\n",
       " 337: 34,\n",
       " 338: 35,\n",
       " 339: 35,\n",
       " 340: 35,\n",
       " 341: 35,\n",
       " 342: 35,\n",
       " 343: 35,\n",
       " 344: 35,\n",
       " 345: 36,\n",
       " 346: 36,\n",
       " 347: 36,\n",
       " 348: 36,\n",
       " 349: 36,\n",
       " 350: 36,\n",
       " 351: 37,\n",
       " 352: 37,\n",
       " 353: 37,\n",
       " 354: 37,\n",
       " 355: 37,\n",
       " 356: 37,\n",
       " 357: 37,\n",
       " 358: 37,\n",
       " 359: 37,\n",
       " 360: 37,\n",
       " 361: 38,\n",
       " 362: 38,\n",
       " 363: 38,\n",
       " 364: 38,\n",
       " 365: 38,\n",
       " 366: 38,\n",
       " 367: 38,\n",
       " 368: 39,\n",
       " 369: 39,\n",
       " 370: 39,\n",
       " 371: 39,\n",
       " 372: 39,\n",
       " 373: 39,\n",
       " 374: 39,\n",
       " 375: 39,\n",
       " 376: 39,\n",
       " 377: 39,\n",
       " 378: 39,\n",
       " 379: 39,\n",
       " 380: 39,\n",
       " 381: 39,\n",
       " 382: 39,\n",
       " 383: 39,\n",
       " 384: 39,\n",
       " 385: 39,\n",
       " 386: 39,\n",
       " 387: 39,\n",
       " 388: 39,\n",
       " 389: 39,\n",
       " 390: 39,\n",
       " 391: 39,\n",
       " 392: 39,\n",
       " 393: 39,\n",
       " 394: 39,\n",
       " 395: 39,\n",
       " 396: 39,\n",
       " 397: 39,\n",
       " 398: 39,\n",
       " 399: 39,\n",
       " 400: 39,\n",
       " 401: 39,\n",
       " 402: 39,\n",
       " 403: 39,\n",
       " 404: 39,\n",
       " 405: 39,\n",
       " 406: 39,\n",
       " 407: 39,\n",
       " 408: 39,\n",
       " 409: 39,\n",
       " 410: 39,\n",
       " 411: 39,\n",
       " 412: 39,\n",
       " 413: 39,\n",
       " 414: 39,\n",
       " 415: 39,\n",
       " 416: 39,\n",
       " 417: 39,\n",
       " 418: 39,\n",
       " 419: 39,\n",
       " 420: 39,\n",
       " 421: 39,\n",
       " 422: 39,\n",
       " 423: 39,\n",
       " 424: 39,\n",
       " 425: 39,\n",
       " 426: 39,\n",
       " 427: 39,\n",
       " 428: 39,\n",
       " 429: 39,\n",
       " 430: 39,\n",
       " 431: 39,\n",
       " 432: 39,\n",
       " 433: 39,\n",
       " 434: 39,\n",
       " 435: 39,\n",
       " 436: 39,\n",
       " 437: 39,\n",
       " 438: 39,\n",
       " 439: 39,\n",
       " 440: 39,\n",
       " 441: 39,\n",
       " 442: 39,\n",
       " 443: 39,\n",
       " 444: 39,\n",
       " 445: 39,\n",
       " 446: 40,\n",
       " 447: 40,\n",
       " 448: 40,\n",
       " 449: 40,\n",
       " 450: 40,\n",
       " 451: 40,\n",
       " 452: 40,\n",
       " 453: 41,\n",
       " 454: 41,\n",
       " 455: 41,\n",
       " 456: 41,\n",
       " 457: 41,\n",
       " 458: 41,\n",
       " 459: 41,\n",
       " 460: 41,\n",
       " 461: 41,\n",
       " 462: 41,\n",
       " 463: 41,\n",
       " 464: 41,\n",
       " 465: 41,\n",
       " 466: 41,\n",
       " 467: 41,\n",
       " 468: 41,\n",
       " 469: 41,\n",
       " 470: 41,\n",
       " 471: 41,\n",
       " 472: 41,\n",
       " 473: 41,\n",
       " 474: 41,\n",
       " 475: 41,\n",
       " 476: 41,\n",
       " 477: 41,\n",
       " 478: 41,\n",
       " 479: 41,\n",
       " 480: 41,\n",
       " 481: 41,\n",
       " 482: 41,\n",
       " 483: 41,\n",
       " 484: 41,\n",
       " 485: 41,\n",
       " 486: 41,\n",
       " 487: 41,\n",
       " 488: 41,\n",
       " 489: 41,\n",
       " 490: 41,\n",
       " 491: 41,\n",
       " 492: 41,\n",
       " 493: 41,\n",
       " 494: 41,\n",
       " 495: 41,\n",
       " 496: 41,\n",
       " 497: 41,\n",
       " 498: 41,\n",
       " 499: 41,\n",
       " 500: 41,\n",
       " 501: 41,\n",
       " 502: 41,\n",
       " 503: 41,\n",
       " 504: 41,\n",
       " 505: 41,\n",
       " 506: 41,\n",
       " 507: 41,\n",
       " 508: 41,\n",
       " 509: 42,\n",
       " 510: 42,\n",
       " 511: 42,\n",
       " 512: 42,\n",
       " 513: 42,\n",
       " 514: 42,\n",
       " 515: 42,\n",
       " 516: 42,\n",
       " 517: 42,\n",
       " 518: 42,\n",
       " 519: 42,\n",
       " 520: 42,\n",
       " 521: 42,\n",
       " 522: 42,\n",
       " 523: 42,\n",
       " 524: 42,\n",
       " 525: 42,\n",
       " 526: 42,\n",
       " 527: 42,\n",
       " 528: 42,\n",
       " 529: 42,\n",
       " 530: 42,\n",
       " 531: 42,\n",
       " 532: 42,\n",
       " 533: 43,\n",
       " 534: 43,\n",
       " 535: 43,\n",
       " 536: 43,\n",
       " 537: 43,\n",
       " 538: 43,\n",
       " 539: 43,\n",
       " 540: 43,\n",
       " 541: 43,\n",
       " 542: 43,\n",
       " 543: 44,\n",
       " 544: 44,\n",
       " 545: 44,\n",
       " 546: 44,\n",
       " 547: 45,\n",
       " 548: 45,\n",
       " 549: 45,\n",
       " 550: 45,\n",
       " 551: 45,\n",
       " 552: 45,\n",
       " 553: 45,\n",
       " 554: 45,\n",
       " 555: 45,\n",
       " 556: 45,\n",
       " 557: 45,\n",
       " 558: 45,\n",
       " 559: 45,\n",
       " 560: 45,\n",
       " 561: 46,\n",
       " 562: 46,\n",
       " 563: 46,\n",
       " 564: 46,\n",
       " 565: 46,\n",
       " 566: 46,\n",
       " 567: 46,\n",
       " 568: 46,\n",
       " 569: 46,\n",
       " 570: 46,\n",
       " 571: 46,\n",
       " 572: 46,\n",
       " 573: 46,\n",
       " 574: 46,\n",
       " 575: 46,\n",
       " 576: 46,\n",
       " 577: 47,\n",
       " 578: 47,\n",
       " 579: 47,\n",
       " 580: 47,\n",
       " 581: 47,\n",
       " 582: 47,\n",
       " 583: 47,\n",
       " 584: 47,\n",
       " 585: 47,\n",
       " 586: 47,\n",
       " 587: 47,\n",
       " 588: 47,\n",
       " 589: 47,\n",
       " 590: 47,\n",
       " 591: 47,\n",
       " 592: 47,\n",
       " 593: 47,\n",
       " 594: 47,\n",
       " 595: 47,\n",
       " 596: 47,\n",
       " 597: 47,\n",
       " 598: 48,\n",
       " 599: 48,\n",
       " 600: 48,\n",
       " 601: 48,\n",
       " 602: 48,\n",
       " 603: 48,\n",
       " 604: 48,\n",
       " 605: 49,\n",
       " 606: 49,\n",
       " 607: 49,\n",
       " 608: 49,\n",
       " 609: 49,\n",
       " 610: 50,\n",
       " 611: 50,\n",
       " 612: 50,\n",
       " 613: 50,\n",
       " 614: 50,\n",
       " 615: 50,\n",
       " 616: 50,\n",
       " 617: 51,\n",
       " 618: 51,\n",
       " 619: 51,\n",
       " 620: 51,\n",
       " 621: 51,\n",
       " 622: 51,\n",
       " 623: 51,\n",
       " 624: 51,\n",
       " 625: 51,\n",
       " 626: 51,\n",
       " 627: 51,\n",
       " 628: 51,\n",
       " 629: 51,\n",
       " 630: 51,\n",
       " 631: 51,\n",
       " 632: 51,\n",
       " 633: 51,\n",
       " 634: 51,\n",
       " 635: 52,\n",
       " 636: 52,\n",
       " 637: 52,\n",
       " 638: 52,\n",
       " 639: 52,\n",
       " 640: 52,\n",
       " 641: 52,\n",
       " 642: 52,\n",
       " 643: 53,\n",
       " 644: 53,\n",
       " 645: 53,\n",
       " 646: 53,\n",
       " 647: 53,\n",
       " 648: 53,\n",
       " 649: 53,\n",
       " 650: 55,\n",
       " 651: 55,\n",
       " 652: 55,\n",
       " 653: 55,\n",
       " 654: 55,\n",
       " 655: 55,\n",
       " 656: 55,\n",
       " 657: 55,\n",
       " 658: 55,\n",
       " 659: 55,\n",
       " 660: 55,\n",
       " 661: 55,\n",
       " 662: 55,\n",
       " 663: 55,\n",
       " 664: 55,\n",
       " 665: 55,\n",
       " 666: 56,\n",
       " 667: 56,\n",
       " 668: 56,\n",
       " 669: 56,\n",
       " 670: 56,\n",
       " 671: 56,\n",
       " 672: 56,\n",
       " 673: 56,\n",
       " 674: 56,\n",
       " 675: 56,\n",
       " 676: 56,\n",
       " 677: 56,\n",
       " 678: 56,\n",
       " 679: 57,\n",
       " 680: 57,\n",
       " 681: 57,\n",
       " 682: 57,\n",
       " 683: 57,\n",
       " 684: 57,\n",
       " 685: 57,\n",
       " 686: 58,\n",
       " 687: 58,\n",
       " 688: 58,\n",
       " 689: 60,\n",
       " 690: 60,\n",
       " 691: 60,\n",
       " 692: 60,\n",
       " 693: 60,\n",
       " 694: 60,\n",
       " 695: 60,\n",
       " 696: 60,\n",
       " 697: 60,\n",
       " 698: 60,\n",
       " 699: 60,\n",
       " 700: 61,\n",
       " 701: 61,\n",
       " 702: 61,\n",
       " 703: 61,\n",
       " 704: 61,\n",
       " 705: 61,\n",
       " 706: 61,\n",
       " 707: 61,\n",
       " 708: 61,\n",
       " 709: 61,\n",
       " 710: 61,\n",
       " 711: 61,\n",
       " 712: 62,\n",
       " 713: 62,\n",
       " 714: 62,\n",
       " 715: 62,\n",
       " 716: 62,\n",
       " 717: 62,\n",
       " 718: 62,\n",
       " 719: 62,\n",
       " 720: 63,\n",
       " 721: 63,\n",
       " 722: 63,\n",
       " 723: 63,\n",
       " 724: 63,\n",
       " 725: 63,\n",
       " 726: 63,\n",
       " 727: 63,\n",
       " 728: 63,\n",
       " 729: 63,\n",
       " 730: 63,\n",
       " 731: 63,\n",
       " 732: 64,\n",
       " 733: 64,\n",
       " 734: 64,\n",
       " 735: 64,\n",
       " 736: 64,\n",
       " 737: 64,\n",
       " 738: 64,\n",
       " 739: 64,\n",
       " 740: 64,\n",
       " 741: 64,\n",
       " 742: 64,\n",
       " 743: 65,\n",
       " 744: 65,\n",
       " 745: 65,\n",
       " 746: 65,\n",
       " 747: 65,\n",
       " 748: 65,\n",
       " 749: 66,\n",
       " 750: 66,\n",
       " 751: 66,\n",
       " 752: 66,\n",
       " 753: 66,\n",
       " 754: 66,\n",
       " 755: 67,\n",
       " 756: 67,\n",
       " 757: 67,\n",
       " 758: 67,\n",
       " 759: 67,\n",
       " 760: 67,\n",
       " 761: 67,\n",
       " 762: 67,\n",
       " 763: 68,\n",
       " 764: 68,\n",
       " 765: 68,\n",
       " 766: 68,\n",
       " 767: 68,\n",
       " 768: 68,\n",
       " 769: 68,\n",
       " 770: 69,\n",
       " 771: 69,\n",
       " 772: 69,\n",
       " 773: 69,\n",
       " 774: 69,\n",
       " 775: 69,\n",
       " 776: 69,\n",
       " 777: 69,\n",
       " 778: 70,\n",
       " 779: 70,\n",
       " 780: 70,\n",
       " 781: 70,\n",
       " 782: 70,\n",
       " 783: 71,\n",
       " 784: 71,\n",
       " 785: 71,\n",
       " 786: 71,\n",
       " 787: 71,\n",
       " 788: 71,\n",
       " 789: 71,\n",
       " 790: 71,\n",
       " 791: 71,\n",
       " 792: 71,\n",
       " 793: 72,\n",
       " 794: 72,\n",
       " 795: 72,\n",
       " 796: 72,\n",
       " 797: 72,\n",
       " 798: 72,\n",
       " 799: 72,\n",
       " 800: 73,\n",
       " 801: 73,\n",
       " 802: 73,\n",
       " 803: 73,\n",
       " 804: 73,\n",
       " 805: 73,\n",
       " 806: 73,\n",
       " 807: 74,\n",
       " 808: 74,\n",
       " 809: 74,\n",
       " 810: 74,\n",
       " 811: 75,\n",
       " 812: 75,\n",
       " 813: 75,\n",
       " 814: 75,\n",
       " 815: 75,\n",
       " 816: 75,\n",
       " 817: 75,\n",
       " 818: 75,\n",
       " 819: 75,\n",
       " 820: 75,\n",
       " 821: 75,\n",
       " 822: 76,\n",
       " 823: 76,\n",
       " 824: 76,\n",
       " 825: 76,\n",
       " 826: 76,\n",
       " 827: 76,\n",
       " 828: 76,\n",
       " 829: 76,\n",
       " 830: 76,\n",
       " 831: 76,\n",
       " 832: 77,\n",
       " 833: 77,\n",
       " 834: 77,\n",
       " 835: 77,\n",
       " 836: 78,\n",
       " 837: 78,\n",
       " 838: 78,\n",
       " 839: 78,\n",
       " 840: 78,\n",
       " 841: 78,\n",
       " 842: 78,\n",
       " 843: 78,\n",
       " 844: 79,\n",
       " 845: 79,\n",
       " 846: 79,\n",
       " 847: 79,\n",
       " 848: 79,\n",
       " 849: 79,\n",
       " 850: 79,\n",
       " 851: 79,\n",
       " 852: 80,\n",
       " 853: 80,\n",
       " 854: 80,\n",
       " 855: 81,\n",
       " 856: 81,\n",
       " 857: 81,\n",
       " 858: 81,\n",
       " 859: 81,\n",
       " 860: 81,\n",
       " 861: 81,\n",
       " 862: 81,\n",
       " 863: 81,\n",
       " 864: 81,\n",
       " 865: 81,\n",
       " 866: 81,\n",
       " 867: 81,\n",
       " 868: 81,\n",
       " 869: 81,\n",
       " 870: 81,\n",
       " 871: 81,\n",
       " 872: 81,\n",
       " 873: 81,\n",
       " 874: 81,\n",
       " 875: 81,\n",
       " 876: 81,\n",
       " 877: 81,\n",
       " 878: 81,\n",
       " 879: 81,\n",
       " 880: 81,\n",
       " 881: 81,\n",
       " 882: 81,\n",
       " 883: 81,\n",
       " 884: 81,\n",
       " 885: 81,\n",
       " 886: 81,\n",
       " 887: 81,\n",
       " 888: 81,\n",
       " 889: 81,\n",
       " 890: 81,\n",
       " 891: 82,\n",
       " 892: 82,\n",
       " 893: 82,\n",
       " 894: 82,\n",
       " 895: 82,\n",
       " 896: 82,\n",
       " 897: 82,\n",
       " 898: 83,\n",
       " 899: 83,\n",
       " 900: 83,\n",
       " 901: 83,\n",
       " 902: 83,\n",
       " 903: 83,\n",
       " 904: 83,\n",
       " 905: 84,\n",
       " 906: 84,\n",
       " 907: 84,\n",
       " 908: 84,\n",
       " 909: 84,\n",
       " 910: 84,\n",
       " 911: 84,\n",
       " 912: 84,\n",
       " 913: 85,\n",
       " 914: 85,\n",
       " 915: 85,\n",
       " 916: 85,\n",
       " 917: 85,\n",
       " 918: 85,\n",
       " 919: 85,\n",
       " 920: 85,\n",
       " 921: 86,\n",
       " 922: 86,\n",
       " 923: 86,\n",
       " 924: 86,\n",
       " 925: 86,\n",
       " 926: 86,\n",
       " 927: 87,\n",
       " 928: 87,\n",
       " 929: 87,\n",
       " 930: 87,\n",
       " 931: 87,\n",
       " 932: 87,\n",
       " 933: 87,\n",
       " 934: 87,\n",
       " 935: 87,\n",
       " 936: 87,\n",
       " 937: 87,\n",
       " 938: 87,\n",
       " 939: 87,\n",
       " 940: 88,\n",
       " 941: 88,\n",
       " 942: 88,\n",
       " 943: 88,\n",
       " 944: 88,\n",
       " 945: 88,\n",
       " 946: 88,\n",
       " 947: 88,\n",
       " 948: 88,\n",
       " 949: 88,\n",
       " 950: 89,\n",
       " 951: 89,\n",
       " 952: 89,\n",
       " 953: 89,\n",
       " 954: 89,\n",
       " 955: 89,\n",
       " 956: 89,\n",
       " 957: 89,\n",
       " 958: 90,\n",
       " 959: 90,\n",
       " 960: 90,\n",
       " 961: 90,\n",
       " 962: 90,\n",
       " 963: 91,\n",
       " 964: 91,\n",
       " 965: 91,\n",
       " 966: 91,\n",
       " 967: 91,\n",
       " 968: 91,\n",
       " 969: 91,\n",
       " 970: 91,\n",
       " 971: 91,\n",
       " 972: 91,\n",
       " 973: 91,\n",
       " 974: 91,\n",
       " 975: 91,\n",
       " 976: 92,\n",
       " 977: 92,\n",
       " 978: 92,\n",
       " 979: 92,\n",
       " 980: 92,\n",
       " 981: 92,\n",
       " 982: 92,\n",
       " 983: 92,\n",
       " 984: 92,\n",
       " 985: 92,\n",
       " 986: 92,\n",
       " 987: 92,\n",
       " 988: 92,\n",
       " 989: 92,\n",
       " 990: 92,\n",
       " 991: 93,\n",
       " 992: 93,\n",
       " 993: 93,\n",
       " 994: 93,\n",
       " 995: 93,\n",
       " 996: 94,\n",
       " 997: 94,\n",
       " 998: 94,\n",
       " 999: 94,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ground_truth = {i: question[\"chunk_id\"] for i, question in enumerate(questions)}\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83a0bb",
   "metadata": {},
   "source": [
    "Build a list of chunk IDs to make sure that the IDs are in sequential order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc08289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_ids_list = [chunk[\"id\"] for chunk in chunks]\n",
    "chunk_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703a989",
   "metadata": {},
   "source": [
    "Pre-load all chunk and question embeddings into NumPy arrays to make similarity calculations efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd78092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = {}\n",
    "question_embeddings = {}\n",
    "\n",
    "for model in models_to_benchmark:\n",
    "    chunk_embeddings[model] = np.array([chunk[\"embeddings\"][model] for chunk in chunks])\n",
    "    question_embeddings[model] = np.array(\n",
    "        [question[\"embeddings\"][model] for question in questions]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca5edb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3072)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings[\"gemini-embedding-001\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eaff27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 3072)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeddings[\"gemini-embedding-001\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca9bbe",
   "metadata": {},
   "source": [
    "## Run the manual benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1891ef4",
   "metadata": {},
   "source": [
    "This loop runs the benchmark for each embedding model:\n",
    "\n",
    "- For each model, it calculates the cosine similarity between every question and all chunks.\n",
    "- For each question, it ranks the chunks by similarity and finds the position (rank) of the correct chunk.\n",
    "- It computes four metrics (MRR, Recall@1, Recall@5, NDCG@5) for each question using the rank.\n",
    "- After processing all questions, it averages the scores for each metric and stores the results for the model.\n",
    "\n",
    "This way, you get a summary of how well each model retrieves the correct chunk for all questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935de679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def get_rank(ranked_chunk_ids: list[int], correct_chunk_id: int) -> int | None:\n",
    "    try:\n",
    "        return ranked_chunk_ids.index(correct_chunk_id) + 1\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "benchmark_results = {}\n",
    "for model_name in tqdm(models_to_benchmark, total=len(models_to_benchmark)):\n",
    "    all_question_embeddings = question_embeddings[model_name]\n",
    "    all_chunk_embeddings = chunk_embeddings[model_name]\n",
    "    similarity_matrix = cosine_similarity(all_question_embeddings, all_chunk_embeddings)\n",
    "\n",
    "    all_mrr_scores = []\n",
    "    all_recall_1_scores = []\n",
    "    all_recall_5_scores = []\n",
    "    all_ndcg_5_scores = []\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        correct_chunk_id = ground_truth[i]\n",
    "        scores_for_this_question = similarity_matrix[i]\n",
    "\n",
    "        chunk_scores = list(zip(chunk_ids_list, scores_for_this_question))\n",
    "        sorted_chunk_scores = sorted(\n",
    "            chunk_scores, key=lambda item: item[1], reverse=True\n",
    "        )\n",
    "        ranked_chunk_ids = [chunk_id for chunk_id, _ in sorted_chunk_scores]\n",
    "\n",
    "        rank = get_rank(ranked_chunk_ids, correct_chunk_id)\n",
    "        all_mrr_scores.append(calculate_mrr(rank))\n",
    "        all_recall_1_scores.append(calculate_recall_at_k(rank, k=1))\n",
    "        all_recall_5_scores.append(calculate_recall_at_k(rank, k=5))\n",
    "        all_ndcg_5_scores.append(calculate_ndcg_at_k(rank, k=5))\n",
    "\n",
    "    benchmark_results[model_name] = {\n",
    "        \"mrr\": np.mean(all_mrr_scores),\n",
    "        \"recall@1\": np.mean(all_recall_1_scores),\n",
    "        \"recall@5\": np.mean(all_recall_5_scores),\n",
    "        \"ndcg@5\": np.mean(all_ndcg_5_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756878c",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38387a77",
   "metadata": {},
   "source": [
    "Find the best scores for each metric to highlight them in the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0964f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mrr': np.float64(0.7424935325893551), 'recall@1': np.float64(0.6360628618693135), 'recall@5': np.float64(0.8941273779983457), 'ndcg@5': np.float64(0.767530255256212)}\n",
      "{'mrr': np.float64(0.5396133238351807), 'recall@1': np.float64(0.4267990074441687), 'recall@5': np.float64(0.6575682382133995), 'ndcg@5': np.float64(0.5500896918946327)}\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"mrr\", \"recall@1\", \"recall@5\", \"ndcg@5\"]\n",
    "max_scores = {metric: -float(\"inf\") for metric in metrics}\n",
    "min_scores = {metric: float(\"inf\") for metric in metrics}\n",
    "\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    for metric in metrics:\n",
    "        if scores[metric] > max_scores[metric]:\n",
    "            max_scores[metric] = scores[metric]\n",
    "        if scores[metric] < min_scores[metric]:\n",
    "            min_scores[metric] = scores[metric]\n",
    "\n",
    "print(max_scores)\n",
    "print(min_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae58cab",
   "metadata": {},
   "source": [
    "Show the benchmark results in a formatted table, highlighting the best and worst scores for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b5fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Model                     </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">    mrr </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@1 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> ndcg@5 </span>┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━┫\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-small    </span>┃ 0.6972 ┃   0.5790 ┃   0.8544 ┃ 0.7261 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-large    </span>┃ 0.6994 ┃   0.5773 ┃   0.8536 ┃ 0.7271 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> all-minilm-l6-v2          </span>┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.5396</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.4268</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.6576</span> ┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.5501</span> ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> gemini-embedding-001      </span>┃ 0.7375 ┃   0.6303 ┃   0.8792 ┃ 0.7639 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-0.6b      </span>┃ 0.7276 ┃   0.6112 ┃   0.8801 ┃ 0.7560 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-8b        </span>┃ 0.7328 ┃   0.6129 ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8941</span> ┃ 0.7643 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-4b        </span>┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7425</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.6361</span> ┃   0.8784 ┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7675</span> ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;95m \u001b[0m\u001b[1;95mModel                    \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95m   mrr\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@1\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mndcg@5\u001b[0m\u001b[1;95m \u001b[0m┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━┫\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-small   \u001b[0m\u001b[33m \u001b[0m┃ 0.6972 ┃   0.5790 ┃   0.8544 ┃ 0.7261 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-large   \u001b[0m\u001b[33m \u001b[0m┃ 0.6994 ┃   0.5773 ┃   0.8536 ┃ 0.7271 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mall-minilm-l6-v2         \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;91m0.5396\u001b[0m ┃   \u001b[1;91m0.4268\u001b[0m ┃   \u001b[1;91m0.6576\u001b[0m ┃ \u001b[1;91m0.5501\u001b[0m ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mgemini-embedding-001     \u001b[0m\u001b[33m \u001b[0m┃ 0.7375 ┃   0.6303 ┃   0.8792 ┃ 0.7639 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-0.6b     \u001b[0m\u001b[33m \u001b[0m┃ 0.7276 ┃   0.6112 ┃   0.8801 ┃ 0.7560 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-8b       \u001b[0m\u001b[33m \u001b[0m┃ 0.7328 ┃   0.6129 ┃   \u001b[1;92m0.8941\u001b[0m ┃ 0.7643 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-4b       \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;92m0.7425\u001b[0m ┃   \u001b[1;92m0.6361\u001b[0m ┃   0.8784 ┃ \u001b[1;92m0.7675\u001b[0m ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.box import HEAVY\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "table = Table(show_header=True, header_style=\"bold bright_magenta\", box=HEAVY)\n",
    "table.add_column(\"Model\", style=\"yellow\", width=25)\n",
    "for metric in metrics:\n",
    "    table.add_column(metric, justify=\"right\")\n",
    "\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    row_data = [model_name]\n",
    "    for metric in metrics:\n",
    "        score = scores[metric]\n",
    "        score_str = f\"{score:.4f}\"\n",
    "\n",
    "        if score == max_scores[metric]:\n",
    "            score_str = f\"[bold bright_green]{score_str}[/bold bright_green]\"\n",
    "        elif score == min_scores[metric]:\n",
    "            score_str = f\"[bold bright_red]{score_str}[/bold bright_red]\"\n",
    "\n",
    "        row_data.append(score_str)\n",
    "\n",
    "    table.add_row(*row_data)\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434375f",
   "metadata": {},
   "source": [
    "If you want to sort the models by their average score across all metrics, you can calculate the average for each model and then sort them accordingly. This way, you can see which models perform best overall, rather than just on individual metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6e37f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Model                     </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">    mrr </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@1 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> ndcg@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Average </span>┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━┫\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">qwen3-embedding-4b</span><span style=\"color: #808000; text-decoration-color: #808000\">        </span>┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7425</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.6361</span> ┃   0.8784 ┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7675</span> ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7561 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> gemini-embedding-001      </span>┃ 0.7375 ┃   0.6303 ┃   0.8792 ┃ 0.7639 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7527 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-8b        </span>┃ 0.7328 ┃   0.6129 ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8941</span> ┃ 0.7643 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7510 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-0.6b      </span>┃ 0.7276 ┃   0.6112 ┃   0.8801 ┃ 0.7560 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7437 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-large    </span>┃ 0.6994 ┃   0.5773 ┃   0.8536 ┃ 0.7271 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7144 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-small    </span>┃ 0.6972 ┃   0.5790 ┃   0.8544 ┃ 0.7261 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7142 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> all-minilm-l6-v2          </span>┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.5396</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.4268</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.6576</span> ┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.5501</span> ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.5435 </span>┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1;95m \u001b[0m\u001b[1;95mModel                    \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95m   mrr\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@1\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mndcg@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mAverage\u001b[0m\u001b[1;95m \u001b[0m┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━┫\n",
       "┃\u001b[33m \u001b[0m\u001b[1;92mqwen3-embedding-4b\u001b[0m\u001b[33m       \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;92m0.7425\u001b[0m ┃   \u001b[1;92m0.6361\u001b[0m ┃   0.8784 ┃ \u001b[1;92m0.7675\u001b[0m ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7561\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mgemini-embedding-001     \u001b[0m\u001b[33m \u001b[0m┃ 0.7375 ┃   0.6303 ┃   0.8792 ┃ 0.7639 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7527\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-8b       \u001b[0m\u001b[33m \u001b[0m┃ 0.7328 ┃   0.6129 ┃   \u001b[1;92m0.8941\u001b[0m ┃ 0.7643 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7510\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-0.6b     \u001b[0m\u001b[33m \u001b[0m┃ 0.7276 ┃   0.6112 ┃   0.8801 ┃ 0.7560 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7437\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-large   \u001b[0m\u001b[33m \u001b[0m┃ 0.6994 ┃   0.5773 ┃   0.8536 ┃ 0.7271 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7144\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-small   \u001b[0m\u001b[33m \u001b[0m┃ 0.6972 ┃   0.5790 ┃   0.8544 ┃ 0.7261 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7142\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mall-minilm-l6-v2         \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;91m0.5396\u001b[0m ┃   \u001b[1;91m0.4268\u001b[0m ┃   \u001b[1;91m0.6576\u001b[0m ┃ \u001b[1;91m0.5501\u001b[0m ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.5435\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.box import HEAVY\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "table = Table(show_header=True, header_style=\"bold bright_magenta\", box=HEAVY)\n",
    "table.add_column(\"Model\", style=\"yellow\", width=25)\n",
    "for metric in metrics:\n",
    "    table.add_column(metric, justify=\"right\")\n",
    "table.add_column(\"Average\", justify=\"right\", style=\"bold cyan\")\n",
    "\n",
    "model_averages = {}\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    average_score = np.mean([scores[metric] for metric in metrics])\n",
    "    model_averages[model_name] = average_score\n",
    "\n",
    "sorted_models = sorted(model_averages.items(), key=lambda x: x[1], reverse=True)\n",
    "best_model_name = sorted_models[0][0]\n",
    "\n",
    "for model_name, avg_score in sorted_models:\n",
    "    model_name_cell_value = model_name\n",
    "    if model_name == best_model_name:\n",
    "        model_name_cell_value = f\"[bold bright_green]{model_name}[/bold bright_green]\"\n",
    "\n",
    "    scores = benchmark_results[model_name]\n",
    "    row_data = [model_name_cell_value]\n",
    "\n",
    "    for metric in metrics:\n",
    "        score = scores[metric]\n",
    "        score_str = f\"{score:.4f}\"\n",
    "\n",
    "        if score == max_scores[metric]:\n",
    "            score_str = f\"[bold bright_green]{score_str}[/bold bright_green]\"\n",
    "        elif score == min_scores[metric]:\n",
    "            score_str = f\"[bold bright_red]{score_str}[/bold bright_red]\"\n",
    "\n",
    "        row_data.append(score_str)\n",
    "\n",
    "    row_data.append(f\"{avg_score:.4f}\")\n",
    "    table.add_row(*row_data)\n",
    "\n",
    "console.print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_embedding_models_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
