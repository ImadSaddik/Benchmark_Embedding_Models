{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be6c22b",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f3990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks    : 43\n",
      "Number of questions : 377\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"../data/embeddings/rog_strix_gaming_notebook_pc_unscanned_file_chunks_embeddings.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "chunks = data[\"chunks\"]\n",
    "questions = data[\"question_answer_pairs\"]\n",
    "\n",
    "print(f\"Number of chunks    : {len(chunks)}\")\n",
    "print(f\"Number of questions : {len(questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f61df1",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "There are several metrics commonly used to benchmark embedding models. In this notebook, you will use the following metrics:\n",
    "\n",
    "- **Mean Reciprocal Rank (MRR)**\n",
    "- **Recall@K**\n",
    "- **Normalized Discounted Cumulative Gain (NDCG)**\n",
    "\n",
    "For more details and additional metrics, see the [ranx metrics documentation](https://amenra.github.io/ranx/metrics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3959df",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank (MRR)\n",
    "\n",
    "MRR measures how quickly the first relevant result appears in the ranked list. The equation is:\n",
    "\n",
    "$$\n",
    "\\text{MRR} = \\frac{1}{\\text{rank}}\n",
    "$$\n",
    "\n",
    "where **rank** is the position of the first relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f5082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculate_mrr(rank: int | None) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "    return 1.0 / rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dca184",
   "metadata": {},
   "source": [
    "### Recall@K\n",
    "\n",
    "Recall@K indicates whether the relevant document appears within the top-$K$ results.  \n",
    "For datasets with one relevant document ($R=1$):\n",
    "\n",
    "$$\n",
    "\\text{Recall@K} = \\frac{r}{R}\n",
    "$$\n",
    "\n",
    "where $r$ is 1 if the relevant document is in the top-$K$, otherwise 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ff37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(rank: int | None, k: int) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "    return 1.0 if rank <= k else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72b463",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG@K)\n",
    "\n",
    "N[DCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)@K evaluates ranking quality, considering the position of the relevant document.  \n",
    "For a single relevant document:\n",
    "\n",
    "$$\n",
    "\\text{DCG@K} = \n",
    "\\begin{cases}\n",
    "\\frac{1}{\\log_2(\\text{rank} + 1)}, & \\text{if rank} \\leq K \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{IDCG@K} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}} = \\text{DCG@K}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f160d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_k(rank: int | None, k: int) -> float:\n",
    "    if rank is None:\n",
    "        return 0.0\n",
    "\n",
    "    if rank <= k:\n",
    "        return 1.0 / math.log2(rank + 1)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f464e9d",
   "metadata": {},
   "source": [
    "## Prepare data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2cd29",
   "metadata": {},
   "source": [
    "Get the list of embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dda7fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all-minilm-l6-v2', 'qwen3-embedding-0.6b', 'gemini-embedding-001', 'qwen3-embedding-4b', 'qwen3-embedding-8b', 'text-embedding-3-small', 'text-embedding-3-large']\n"
     ]
    }
   ],
   "source": [
    "models_to_benchmark = list(chunks[0][\"embeddings\"].keys())\n",
    "print(models_to_benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc4a18",
   "metadata": {},
   "source": [
    "Create a mapping from each question to its correct chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9af601c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 1,\n",
       " 9: 1,\n",
       " 10: 1,\n",
       " 11: 1,\n",
       " 12: 2,\n",
       " 13: 2,\n",
       " 14: 2,\n",
       " 15: 2,\n",
       " 16: 2,\n",
       " 17: 2,\n",
       " 18: 2,\n",
       " 19: 2,\n",
       " 20: 3,\n",
       " 21: 3,\n",
       " 22: 3,\n",
       " 23: 4,\n",
       " 24: 4,\n",
       " 25: 4,\n",
       " 26: 4,\n",
       " 27: 4,\n",
       " 28: 4,\n",
       " 29: 4,\n",
       " 30: 4,\n",
       " 31: 4,\n",
       " 32: 4,\n",
       " 33: 4,\n",
       " 34: 4,\n",
       " 35: 4,\n",
       " 36: 4,\n",
       " 37: 4,\n",
       " 38: 4,\n",
       " 39: 4,\n",
       " 40: 4,\n",
       " 41: 4,\n",
       " 42: 4,\n",
       " 43: 4,\n",
       " 44: 4,\n",
       " 45: 4,\n",
       " 46: 4,\n",
       " 47: 4,\n",
       " 48: 4,\n",
       " 49: 4,\n",
       " 50: 4,\n",
       " 51: 4,\n",
       " 52: 4,\n",
       " 53: 4,\n",
       " 54: 4,\n",
       " 55: 4,\n",
       " 56: 4,\n",
       " 57: 4,\n",
       " 58: 4,\n",
       " 59: 5,\n",
       " 60: 5,\n",
       " 61: 5,\n",
       " 62: 5,\n",
       " 63: 5,\n",
       " 64: 5,\n",
       " 65: 5,\n",
       " 66: 6,\n",
       " 67: 6,\n",
       " 68: 6,\n",
       " 69: 6,\n",
       " 70: 6,\n",
       " 71: 6,\n",
       " 72: 6,\n",
       " 73: 7,\n",
       " 74: 7,\n",
       " 75: 7,\n",
       " 76: 7,\n",
       " 77: 7,\n",
       " 78: 7,\n",
       " 79: 7,\n",
       " 80: 7,\n",
       " 81: 8,\n",
       " 82: 8,\n",
       " 83: 8,\n",
       " 84: 8,\n",
       " 85: 8,\n",
       " 86: 8,\n",
       " 87: 8,\n",
       " 88: 8,\n",
       " 89: 9,\n",
       " 90: 9,\n",
       " 91: 9,\n",
       " 92: 9,\n",
       " 93: 9,\n",
       " 94: 9,\n",
       " 95: 10,\n",
       " 96: 10,\n",
       " 97: 10,\n",
       " 98: 10,\n",
       " 99: 10,\n",
       " 100: 10,\n",
       " 101: 10,\n",
       " 102: 10,\n",
       " 103: 10,\n",
       " 104: 10,\n",
       " 105: 10,\n",
       " 106: 10,\n",
       " 107: 10,\n",
       " 108: 11,\n",
       " 109: 11,\n",
       " 110: 11,\n",
       " 111: 11,\n",
       " 112: 11,\n",
       " 113: 11,\n",
       " 114: 11,\n",
       " 115: 11,\n",
       " 116: 11,\n",
       " 117: 11,\n",
       " 118: 12,\n",
       " 119: 12,\n",
       " 120: 12,\n",
       " 121: 12,\n",
       " 122: 12,\n",
       " 123: 12,\n",
       " 124: 12,\n",
       " 125: 12,\n",
       " 126: 13,\n",
       " 127: 13,\n",
       " 128: 13,\n",
       " 129: 13,\n",
       " 130: 13,\n",
       " 131: 14,\n",
       " 132: 14,\n",
       " 133: 14,\n",
       " 134: 14,\n",
       " 135: 14,\n",
       " 136: 14,\n",
       " 137: 14,\n",
       " 138: 14,\n",
       " 139: 14,\n",
       " 140: 14,\n",
       " 141: 14,\n",
       " 142: 14,\n",
       " 143: 14,\n",
       " 144: 15,\n",
       " 145: 15,\n",
       " 146: 15,\n",
       " 147: 15,\n",
       " 148: 15,\n",
       " 149: 15,\n",
       " 150: 15,\n",
       " 151: 15,\n",
       " 152: 15,\n",
       " 153: 15,\n",
       " 154: 15,\n",
       " 155: 15,\n",
       " 156: 15,\n",
       " 157: 15,\n",
       " 158: 15,\n",
       " 159: 16,\n",
       " 160: 16,\n",
       " 161: 16,\n",
       " 162: 16,\n",
       " 163: 16,\n",
       " 164: 17,\n",
       " 165: 17,\n",
       " 166: 17,\n",
       " 167: 17,\n",
       " 168: 17,\n",
       " 169: 17,\n",
       " 170: 17,\n",
       " 171: 17,\n",
       " 172: 17,\n",
       " 173: 17,\n",
       " 174: 17,\n",
       " 175: 18,\n",
       " 176: 18,\n",
       " 177: 18,\n",
       " 178: 18,\n",
       " 179: 18,\n",
       " 180: 18,\n",
       " 181: 18,\n",
       " 182: 18,\n",
       " 183: 18,\n",
       " 184: 18,\n",
       " 185: 18,\n",
       " 186: 18,\n",
       " 187: 19,\n",
       " 188: 19,\n",
       " 189: 19,\n",
       " 190: 19,\n",
       " 191: 19,\n",
       " 192: 19,\n",
       " 193: 20,\n",
       " 194: 20,\n",
       " 195: 20,\n",
       " 196: 21,\n",
       " 197: 21,\n",
       " 198: 21,\n",
       " 199: 21,\n",
       " 200: 22,\n",
       " 201: 22,\n",
       " 202: 22,\n",
       " 203: 22,\n",
       " 204: 22,\n",
       " 205: 22,\n",
       " 206: 23,\n",
       " 207: 23,\n",
       " 208: 23,\n",
       " 209: 23,\n",
       " 210: 23,\n",
       " 211: 23,\n",
       " 212: 23,\n",
       " 213: 24,\n",
       " 214: 24,\n",
       " 215: 24,\n",
       " 216: 24,\n",
       " 217: 24,\n",
       " 218: 24,\n",
       " 219: 24,\n",
       " 220: 24,\n",
       " 221: 24,\n",
       " 222: 24,\n",
       " 223: 24,\n",
       " 224: 25,\n",
       " 225: 25,\n",
       " 226: 25,\n",
       " 227: 25,\n",
       " 228: 25,\n",
       " 229: 26,\n",
       " 230: 26,\n",
       " 231: 26,\n",
       " 232: 26,\n",
       " 233: 27,\n",
       " 234: 27,\n",
       " 235: 27,\n",
       " 236: 27,\n",
       " 237: 27,\n",
       " 238: 28,\n",
       " 239: 28,\n",
       " 240: 28,\n",
       " 241: 28,\n",
       " 242: 28,\n",
       " 243: 29,\n",
       " 244: 29,\n",
       " 245: 29,\n",
       " 246: 29,\n",
       " 247: 29,\n",
       " 248: 29,\n",
       " 249: 29,\n",
       " 250: 29,\n",
       " 251: 30,\n",
       " 252: 30,\n",
       " 253: 30,\n",
       " 254: 30,\n",
       " 255: 30,\n",
       " 256: 30,\n",
       " 257: 31,\n",
       " 258: 31,\n",
       " 259: 31,\n",
       " 260: 31,\n",
       " 261: 31,\n",
       " 262: 31,\n",
       " 263: 31,\n",
       " 264: 31,\n",
       " 265: 31,\n",
       " 266: 31,\n",
       " 267: 31,\n",
       " 268: 31,\n",
       " 269: 31,\n",
       " 270: 31,\n",
       " 271: 31,\n",
       " 272: 32,\n",
       " 273: 32,\n",
       " 274: 32,\n",
       " 275: 32,\n",
       " 276: 32,\n",
       " 277: 32,\n",
       " 278: 32,\n",
       " 279: 32,\n",
       " 280: 32,\n",
       " 281: 32,\n",
       " 282: 32,\n",
       " 283: 33,\n",
       " 284: 33,\n",
       " 285: 33,\n",
       " 286: 33,\n",
       " 287: 33,\n",
       " 288: 33,\n",
       " 289: 33,\n",
       " 290: 33,\n",
       " 291: 34,\n",
       " 292: 34,\n",
       " 293: 34,\n",
       " 294: 34,\n",
       " 295: 35,\n",
       " 296: 35,\n",
       " 297: 35,\n",
       " 298: 35,\n",
       " 299: 35,\n",
       " 300: 36,\n",
       " 301: 36,\n",
       " 302: 36,\n",
       " 303: 36,\n",
       " 304: 36,\n",
       " 305: 36,\n",
       " 306: 37,\n",
       " 307: 37,\n",
       " 308: 37,\n",
       " 309: 37,\n",
       " 310: 37,\n",
       " 311: 37,\n",
       " 312: 37,\n",
       " 313: 37,\n",
       " 314: 38,\n",
       " 315: 38,\n",
       " 316: 38,\n",
       " 317: 38,\n",
       " 318: 38,\n",
       " 319: 38,\n",
       " 320: 38,\n",
       " 321: 38,\n",
       " 322: 39,\n",
       " 323: 39,\n",
       " 324: 39,\n",
       " 325: 39,\n",
       " 326: 39,\n",
       " 327: 39,\n",
       " 328: 39,\n",
       " 329: 39,\n",
       " 330: 39,\n",
       " 331: 39,\n",
       " 332: 40,\n",
       " 333: 40,\n",
       " 334: 40,\n",
       " 335: 40,\n",
       " 336: 40,\n",
       " 337: 40,\n",
       " 338: 40,\n",
       " 339: 40,\n",
       " 340: 40,\n",
       " 341: 41,\n",
       " 342: 41,\n",
       " 343: 41,\n",
       " 344: 41,\n",
       " 345: 41,\n",
       " 346: 41,\n",
       " 347: 42,\n",
       " 348: 42,\n",
       " 349: 42,\n",
       " 350: 42,\n",
       " 351: 42,\n",
       " 352: 42,\n",
       " 353: 42,\n",
       " 354: 42,\n",
       " 355: 42,\n",
       " 356: 42,\n",
       " 357: 42,\n",
       " 358: 42,\n",
       " 359: 42,\n",
       " 360: 42,\n",
       " 361: 42,\n",
       " 362: 42,\n",
       " 363: 42,\n",
       " 364: 42,\n",
       " 365: 42,\n",
       " 366: 42,\n",
       " 367: 42,\n",
       " 368: 42,\n",
       " 369: 42,\n",
       " 370: 42,\n",
       " 371: 42,\n",
       " 372: 42,\n",
       " 373: 42,\n",
       " 374: 42,\n",
       " 375: 42,\n",
       " 376: 42}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ground_truth = {i: question[\"chunk_id\"] for i, question in enumerate(questions)}\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83a0bb",
   "metadata": {},
   "source": [
    "Build a list of chunk IDs to make sure that the IDs are in sequential order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc08289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_ids_list = [chunk[\"id\"] for chunk in chunks]\n",
    "chunk_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703a989",
   "metadata": {},
   "source": [
    "Pre-load all chunk and question embeddings into NumPy arrays to make similarity calculations efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd78092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = {}\n",
    "question_embeddings = {}\n",
    "\n",
    "for model in models_to_benchmark:\n",
    "    chunk_embeddings[model] = np.array([chunk[\"embeddings\"][model] for chunk in chunks])\n",
    "    question_embeddings[model] = np.array(\n",
    "        [question[\"embeddings\"][model] for question in questions]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca5edb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings[\"gemini-embedding-001\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eaff27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeddings[\"gemini-embedding-001\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca9bbe",
   "metadata": {},
   "source": [
    "## Run the manual benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1891ef4",
   "metadata": {},
   "source": [
    "This loop runs the benchmark for each embedding model:\n",
    "\n",
    "- For each model, it calculates the cosine similarity between every question and all chunks.\n",
    "- For each question, it ranks the chunks by similarity and finds the position (rank) of the correct chunk.\n",
    "- It computes four metrics (MRR, Recall@1, Recall@5, NDCG@5) for each question using the rank.\n",
    "- After processing all questions, it averages the scores for each metric and stores the results for the model.\n",
    "\n",
    "This way, you get a summary of how well each model retrieves the correct chunk for all questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935de679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 61.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def get_rank(ranked_chunk_ids: list[int], correct_chunk_id: int) -> int | None:\n",
    "    try:\n",
    "        return ranked_chunk_ids.index(correct_chunk_id) + 1\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "benchmark_results = {}\n",
    "for model_name in tqdm(models_to_benchmark, total=len(models_to_benchmark)):\n",
    "    all_question_embeddings = question_embeddings[model_name]\n",
    "    all_chunk_embeddings = chunk_embeddings[model_name]\n",
    "    similarity_matrix = cosine_similarity(all_question_embeddings, all_chunk_embeddings)\n",
    "\n",
    "    all_mrr_scores = []\n",
    "    all_recall_1_scores = []\n",
    "    all_recall_5_scores = []\n",
    "    all_ndcg_5_scores = []\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        correct_chunk_id = ground_truth[i]\n",
    "        scores_for_this_question = similarity_matrix[i]\n",
    "\n",
    "        chunk_scores = list(zip(chunk_ids_list, scores_for_this_question))\n",
    "        sorted_chunk_scores = sorted(\n",
    "            chunk_scores, key=lambda item: item[1], reverse=True\n",
    "        )\n",
    "        ranked_chunk_ids = [chunk_id for chunk_id, _ in sorted_chunk_scores]\n",
    "\n",
    "        rank = get_rank(ranked_chunk_ids, correct_chunk_id)\n",
    "        all_mrr_scores.append(calculate_mrr(rank))\n",
    "        all_recall_1_scores.append(calculate_recall_at_k(rank, k=1))\n",
    "        all_recall_5_scores.append(calculate_recall_at_k(rank, k=5))\n",
    "        all_ndcg_5_scores.append(calculate_ndcg_at_k(rank, k=5))\n",
    "\n",
    "    benchmark_results[model_name] = {\n",
    "        \"mrr\": np.mean(all_mrr_scores),\n",
    "        \"recall@1\": np.mean(all_recall_1_scores),\n",
    "        \"recall@5\": np.mean(all_recall_5_scores),\n",
    "        \"ndcg@5\": np.mean(all_ndcg_5_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756878c",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38387a77",
   "metadata": {},
   "source": [
    "Find the best scores for each metric to highlight them in the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0964f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mrr': np.float64(0.8389737436156535), 'recall@1': np.float64(0.7480106100795756), 'recall@5': np.float64(0.9681697612732095), 'ndcg@5': np.float64(0.8683514691382817)}\n",
      "{'mrr': np.float64(0.7120984864084288), 'recall@1': np.float64(0.6127320954907162), 'recall@5': np.float64(0.8408488063660478), 'ndcg@5': np.float64(0.7340709524343748)}\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"mrr\", \"recall@1\", \"recall@5\", \"ndcg@5\"]\n",
    "max_scores = {metric: -float(\"inf\") for metric in metrics}\n",
    "min_scores = {metric: float(\"inf\") for metric in metrics}\n",
    "\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    for metric in metrics:\n",
    "        if scores[metric] > max_scores[metric]:\n",
    "            max_scores[metric] = scores[metric]\n",
    "        if scores[metric] < min_scores[metric]:\n",
    "            min_scores[metric] = scores[metric]\n",
    "\n",
    "print(max_scores)\n",
    "print(min_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae58cab",
   "metadata": {},
   "source": [
    "Show the benchmark results in a formatted table, highlighting the best and worst scores for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b5fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Model                     </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">    mrr </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@1 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> ndcg@5 </span>┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━┫\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> all-minilm-l6-v2          </span>┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.7121</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.6127</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.8408</span> ┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.7341</span> ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-0.6b      </span>┃ 0.8075 ┃   0.7188 ┃   0.9098 ┃ 0.8254 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> gemini-embedding-001      </span>┃ 0.7836 ┃   0.7029 ┃   0.8886 ┃ 0.8015 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-4b        </span>┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8390</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7480</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.9682</span> ┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8684</span> ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-8b        </span>┃ 0.8307 ┃   0.7401 ┃   0.9496 ┃ 0.8559 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-small    </span>┃ 0.7851 ┃   0.7056 ┃   0.8859 ┃ 0.8028 ┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-large    </span>┃ 0.7847 ┃   0.7003 ┃   0.8780 ┃ 0.7991 ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;95m \u001b[0m\u001b[1;95mModel                    \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95m   mrr\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@1\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mndcg@5\u001b[0m\u001b[1;95m \u001b[0m┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━┫\n",
       "┃\u001b[33m \u001b[0m\u001b[33mall-minilm-l6-v2         \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;91m0.7121\u001b[0m ┃   \u001b[1;91m0.6127\u001b[0m ┃   \u001b[1;91m0.8408\u001b[0m ┃ \u001b[1;91m0.7341\u001b[0m ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-0.6b     \u001b[0m\u001b[33m \u001b[0m┃ 0.8075 ┃   0.7188 ┃   0.9098 ┃ 0.8254 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mgemini-embedding-001     \u001b[0m\u001b[33m \u001b[0m┃ 0.7836 ┃   0.7029 ┃   0.8886 ┃ 0.8015 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-4b       \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;92m0.8390\u001b[0m ┃   \u001b[1;92m0.7480\u001b[0m ┃   \u001b[1;92m0.9682\u001b[0m ┃ \u001b[1;92m0.8684\u001b[0m ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-8b       \u001b[0m\u001b[33m \u001b[0m┃ 0.8307 ┃   0.7401 ┃   0.9496 ┃ 0.8559 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-small   \u001b[0m\u001b[33m \u001b[0m┃ 0.7851 ┃   0.7056 ┃   0.8859 ┃ 0.8028 ┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-large   \u001b[0m\u001b[33m \u001b[0m┃ 0.7847 ┃   0.7003 ┃   0.8780 ┃ 0.7991 ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.box import HEAVY\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "table = Table(show_header=True, header_style=\"bold bright_magenta\", box=HEAVY)\n",
    "table.add_column(\"Model\", style=\"yellow\", width=25)\n",
    "for metric in metrics:\n",
    "    table.add_column(metric, justify=\"right\")\n",
    "\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    row_data = [model_name]\n",
    "    for metric in metrics:\n",
    "        score = scores[metric]\n",
    "        score_str = f\"{score:.4f}\"\n",
    "\n",
    "        if score == max_scores[metric]:\n",
    "            score_str = f\"[bold bright_green]{score_str}[/bold bright_green]\"\n",
    "        elif score == min_scores[metric]:\n",
    "            score_str = f\"[bold bright_red]{score_str}[/bold bright_red]\"\n",
    "\n",
    "        row_data.append(score_str)\n",
    "\n",
    "    table.add_row(*row_data)\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434375f",
   "metadata": {},
   "source": [
    "If you want to sort the models by their average score across all metrics, you can calculate the average for each model and then sort them accordingly. This way, you can see which models perform best overall, rather than just on individual metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6e37f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Model                     </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">    mrr </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@1 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> recall@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> ndcg@5 </span>┃<span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"> Average </span>┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━┫\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">qwen3-embedding-4b</span><span style=\"color: #808000; text-decoration-color: #808000\">        </span>┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8390</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.7480</span> ┃   <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.9682</span> ┃ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0.8684</span> ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.8559 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-8b        </span>┃ 0.8307 ┃   0.7401 ┃   0.9496 ┃ 0.8559 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.8441 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> qwen3-embedding-0.6b      </span>┃ 0.8075 ┃   0.7188 ┃   0.9098 ┃ 0.8254 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.8154 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-small    </span>┃ 0.7851 ┃   0.7056 ┃   0.8859 ┃ 0.8028 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7948 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> gemini-embedding-001      </span>┃ 0.7836 ┃   0.7029 ┃   0.8886 ┃ 0.8015 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7941 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> text-embedding-3-large    </span>┃ 0.7847 ┃   0.7003 ┃   0.8780 ┃ 0.7991 ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7905 </span>┃\n",
       "┃<span style=\"color: #808000; text-decoration-color: #808000\"> all-minilm-l6-v2          </span>┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.7121</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.6127</span> ┃   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.8408</span> ┃ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">0.7341</span> ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  0.7249 </span>┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1;95m \u001b[0m\u001b[1;95mModel                    \u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95m   mrr\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@1\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mrecall@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mndcg@5\u001b[0m\u001b[1;95m \u001b[0m┃\u001b[1;95m \u001b[0m\u001b[1;95mAverage\u001b[0m\u001b[1;95m \u001b[0m┃\n",
       "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━╋━━━━━━━━━┫\n",
       "┃\u001b[33m \u001b[0m\u001b[1;92mqwen3-embedding-4b\u001b[0m\u001b[33m       \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;92m0.8390\u001b[0m ┃   \u001b[1;92m0.7480\u001b[0m ┃   \u001b[1;92m0.9682\u001b[0m ┃ \u001b[1;92m0.8684\u001b[0m ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.8559\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-8b       \u001b[0m\u001b[33m \u001b[0m┃ 0.8307 ┃   0.7401 ┃   0.9496 ┃ 0.8559 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.8441\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mqwen3-embedding-0.6b     \u001b[0m\u001b[33m \u001b[0m┃ 0.8075 ┃   0.7188 ┃   0.9098 ┃ 0.8254 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.8154\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-small   \u001b[0m\u001b[33m \u001b[0m┃ 0.7851 ┃   0.7056 ┃   0.8859 ┃ 0.8028 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7948\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mgemini-embedding-001     \u001b[0m\u001b[33m \u001b[0m┃ 0.7836 ┃   0.7029 ┃   0.8886 ┃ 0.8015 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7941\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mtext-embedding-3-large   \u001b[0m\u001b[33m \u001b[0m┃ 0.7847 ┃   0.7003 ┃   0.8780 ┃ 0.7991 ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7905\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┃\u001b[33m \u001b[0m\u001b[33mall-minilm-l6-v2         \u001b[0m\u001b[33m \u001b[0m┃ \u001b[1;91m0.7121\u001b[0m ┃   \u001b[1;91m0.6127\u001b[0m ┃   \u001b[1;91m0.8408\u001b[0m ┃ \u001b[1;91m0.7341\u001b[0m ┃\u001b[1;36m \u001b[0m\u001b[1;36m 0.7249\u001b[0m\u001b[1;36m \u001b[0m┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━┻━━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.box import HEAVY\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "table = Table(show_header=True, header_style=\"bold bright_magenta\", box=HEAVY)\n",
    "table.add_column(\"Model\", style=\"yellow\", width=25)\n",
    "for metric in metrics:\n",
    "    table.add_column(metric, justify=\"right\")\n",
    "table.add_column(\"Average\", justify=\"right\", style=\"bold cyan\")\n",
    "\n",
    "model_averages = {}\n",
    "for model_name, scores in benchmark_results.items():\n",
    "    average_score = np.mean([scores[metric] for metric in metrics])\n",
    "    model_averages[model_name] = average_score\n",
    "\n",
    "sorted_models = sorted(model_averages.items(), key=lambda x: x[1], reverse=True)\n",
    "best_model_name = sorted_models[0][0]\n",
    "\n",
    "for model_name, avg_score in sorted_models:\n",
    "    model_name_cell_value = model_name\n",
    "    if model_name == best_model_name:\n",
    "        model_name_cell_value = f\"[bold bright_green]{model_name}[/bold bright_green]\"\n",
    "\n",
    "    scores = benchmark_results[model_name]\n",
    "    row_data = [model_name_cell_value]\n",
    "\n",
    "    for metric in metrics:\n",
    "        score = scores[metric]\n",
    "        score_str = f\"{score:.4f}\"\n",
    "\n",
    "        if score == max_scores[metric]:\n",
    "            score_str = f\"[bold bright_green]{score_str}[/bold bright_green]\"\n",
    "        elif score == min_scores[metric]:\n",
    "            score_str = f\"[bold bright_red]{score_str}[/bold bright_red]\"\n",
    "\n",
    "        row_data.append(score_str)\n",
    "\n",
    "    row_data.append(f\"{avg_score:.4f}\")\n",
    "    table.add_row(*row_data)\n",
    "\n",
    "console.print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_embedding_models_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
