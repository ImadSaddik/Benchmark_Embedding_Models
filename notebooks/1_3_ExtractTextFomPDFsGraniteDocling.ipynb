{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ad8955",
   "metadata": {},
   "source": [
    "# Extract text from PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926225bc",
   "metadata": {},
   "source": [
    "Extracting text from PDFs is challenging because these files may be scanned, have complex layouts, or contain unstructured data such as images and tables. When building a dataset to benchmark embedding models, it is important to avoid noisy, poorly formatted, or merged text between sections.\n",
    "\n",
    "Libraries like [PyMuPDF](https://github.com/pymupdf/PyMuPDF), [PyPDF2](https://github.com/py-pdf/pypdf), and [pdfplumber](https://github.com/jsvine/pdfplumber) can extract text from simple PDFs. However, they are ineffective when dealing with unstructured data or scanned documents. Embedding models, unlike LLMs, cannot interpret the context or structure of a document. They simply embed whatever text they receive, regardless of its quality.\n",
    "\n",
    "Therefore, it is essential to ensure that the extracted text is clean and well-structured. Modern LLMs excel at reading images and understanding text, allowing us to leverage them to extract text from PDFs in a format that closely matches how a human would perceive the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f1c26",
   "metadata": {},
   "source": [
    "## Granite docling 258M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899fae6",
   "metadata": {},
   "source": [
    "### Using the transformers library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16284ac0",
   "metadata": {},
   "source": [
    "Start by initializing the model and processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0741562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_name = \"ibm-granite/granite-docling-258M\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "granite_docling_processor = AutoProcessor.from_pretrained(model_name)\n",
    "granite_docling_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    dtype=torch.bfloat16,\n",
    ").to(device)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454ae06",
   "metadata": {},
   "source": [
    "Prepare the input to be passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97686529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "\n",
    "# Provide a URL or a PIL image\n",
    "image_path = \"../images/test_ocr.png\"\n",
    "image = Image.open(image_path)\n",
    "image = load_image(image=image_path)\n",
    "# image = load_image(\n",
    "#     \"https://huggingface.co/ibm-granite/granite-docling-258M/resolve/main/assets/new_arxiv.png\"\n",
    "# )\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Convert this page to docling.\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = granite_docling_processor.apply_chat_template(\n",
    "    conversation=messages, add_generation_prompt=True\n",
    ")\n",
    "inputs = granite_docling_processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a8f5a",
   "metadata": {},
   "source": [
    "Generate the output, which will contain the extracted text. Even with a GPU, it took around 5 minutes to process just one image. The `doc_tags` variable contains the raw output from the model.\n",
    "\n",
    "**Edit:** I found a solution to the slowness issue. You need to explicitely set `use_cache` to `True` to use KV caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7941b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = granite_docling_model.generate(\n",
    "    **inputs, max_new_tokens=8192, use_cache=True\n",
    ")\n",
    "prompt_length = inputs.input_ids.shape[1]\n",
    "trimmed_generated_ids = generated_ids[:, prompt_length:]\n",
    "doc_tags = granite_docling_processor.batch_decode(\n",
    "    trimmed_generated_ids,\n",
    "    skip_special_tokens=False,\n",
    ")[0].lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd9151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doctag><page_header><loc_115><loc_27><loc_385><loc_34>Energy Budget of WASP-121 b from JWST/NIRISS Phase Curve</page_header>\n",
      "<page_header><loc_454><loc_28><loc_459><loc_34>9</page_header>\n",
      "<text><loc_41><loc_42><loc_239><loc_88>while the kernel weights are structured as ( N$_{slice}$ , N$_{time}$ ). This precomputation significantly accelerates our calculations, which is essential since the longitudinal slices are at least partially degenerate with one another. Consequently, the fits require more steps and walkers to ensure proper convergence.</text>\n",
      "<text><loc_41><loc_89><loc_239><loc_206>To address this, we follow a similar approach to our sinusoidal fits using emcee , but we increase the total number of steps to 100,000 and use 100 walkers. Na¨ıvely, the fit would include 2 N$_{slice}$ + 1 parameters: N$_{slice}$ for the albedo values, N$_{slice}$ for the emission parameters, and one additional scatter parameter, σ . However, since night-side slices do not contribute to the reflected light component, we exclude these albedo values from the fit. In any case, our choice of 100 walkers ensures a sufficient number of walkers per free parameter. Following Coulombe et al. (2025) we set an upper prior limit of 3 / 2 on all albedo slices as a fully Lambertian sphere ( A$_{i}$ = 1 ) corresponds to a geometric albedo of A$_{g}$ = 2 / 3. For thermal emission we impose a uniform prior between 0 and 500 ppm for each slice.</text>\n",
      "<text><loc_41><loc_207><loc_239><loc_269>We choose to fit our detrended lightcurves considering 4, 6 and 8 longitudinal slices ( N$_{slice}$ = 4 , 6 , 8). However, we show the results of the simplest 4 slice model. As in our previous fits, we conduct an initial run with 25,000 steps (25% of the total run) and use the maximumprobability parameters from this preliminary fit as the starting positions for the final 75,000-step run. We then discard the first 60% of the final run as burn-in.</text>\n",
      "<section_header_level_1><loc_73><loc_276><loc_207><loc_283>2.5. Planetary Effective Temperature</section_header_level_1>\n",
      "<text><loc_41><loc_286><loc_239><loc_348>Phase curves are the only way to probe thermal emission from the day and nightside of an exoplanet and hence determine its global energy budget (Partier & Crossfield 2018). The wavelength range of NIRISS/SOSS covers a large portion of the emitted flux of WASP-121 b ( ∼ 50-83%; see Figure 2), enabling a precise and robust constraint of the planet's energy budget.</text>\n",
      "<text><loc_41><loc_349><loc_239><loc_364>We convert the fitted F$_{p}$ / F$_{∗}$ emission spectra to brightness temperature by wavelength,</text>\n",
      "<formula><loc_60><loc_368><loc_238><loc_387>T _ { b r i g h t } = \\frac { h c } { k \\lambda } \\cdot \\left [ \\ln \\left ( \\frac { 2 b c ^ { 2 } } { \\lambda ^ { 5 } B _ { \\lambda , p l a n e t } } + 1 \\right ) \\right ] ^ { - 1 } ,</formula>\n",
      "<text><loc_41><loc_391><loc_178><loc_398>where the planet's thermal emission is</text>\n",
      "<formula><loc_84><loc_403><loc_238><loc_419>B _ { \\lambda , \\text {planet} } = \\frac { F _ { p } / F _ { * } } { ( R _ { p } / R _ { * } ) ^ { 2 } } \\cdot B _ { \\lambda , \\text {star} } \\, .</formula>\n",
      "<text><loc_41><loc_425><loc_239><loc_455>There are many ways of converting brightness temperatures to effective temperature, including the ErrorWeighted Mean (EWM), Power-Weighted mean (PWM) and with a Gaussian Process (Schwartz & Cowan 2015;</text>\n",
      "<chart><loc_273><loc_49><loc_454><loc_134><line_chart><caption><loc_261><loc_141><loc_459><loc_264>Figure 2. Estimated captured flux of the planet assuming the planet radiates as a blackbody. The captured flux is calculated as the ratio of the integrated blackbody emission within the instrument's band pass to the total emission over all wavelengths, i.e., γ = ∫ λ$_{max}$ λ$_{min}$ B ( λ, T ) dλ/ ∫ ∞ 0 B ( λ, T ) dλ . The captured flux fraction is shown for NIRISS SOSS [0.6-2.85 µ m] (red line); Hubble WFC3 [1.12-1.64 µ m] (dashed green line); NIRSpec G395H [2.7-5.15 µ m] (dash dotted blue line). The red-shaded region shows the temperature range on WASP-121 b based on our T$_{eff}$ estimates. Red dashed lines indicate the boundaries of the planet's temperature range within the NIRISS SOSS captured flux fraction. From this we estimate that these observations capture between 55% and 82% of the planet's bolometric flux, depending on orbital phase. Using the minimum temperature from the NAMELESS fit, this estimate decreases to 50%. In either case, the wavelength coverage of NIRISS exceeds that of any other instrument.</caption></chart>\n",
      "<text><loc_261><loc_273><loc_459><loc_359>Pass et al. 2019). In this work, we elect to compute our effective temperature estimates with a novel method that is essentially a combination of the PWM and EWM. We create the effective temperature by using a simple Monte Carlo process. First, we perturb our F$_{p}$ / F$_{s}$ emission spectra at each point in the orbit by a Gaussian based on the measurement uncertainty. Our new emission spectrum is then used to create an estimate of the brightness temperature spectrum. This process is repeated at each orbital phase. We then estimate the effective temperature, T$_{eff}$ for a given orbital phase as</text>\n",
      "<formula><loc_317><loc_362><loc_459><loc_382>T _ { \\text {eff} } = \\frac { \\sum _ { i = 1 } ^ { N } w _ { i } T _ { \\text {bright,} } , } { \\sum _ { i = 1 } ^ { N } w _ { i } } ,</formula>\n",
      "<text><loc_261><loc_384><loc_459><loc_414>where w$_{i}$ is the weight for the i -th wavelength given by the fraction of the planet's bolometric flux that falls within that wavelength bin scaled by the inverse variance of the measurement,</text>\n",
      "<formula><loc_305><loc_417><loc_459><loc_437>w _ { i } = \\frac { \\int _ { \\lambda _ { i } } ^ { \\lambda _ { i } + 1 } B ( \\lambda _ { i } , T _ { \\text {est} } ) \\, d \\lambda } { \\int _ { 0 } ^ { \\infty } B ( \\lambda _ { i } , T _ { \\text {est} } ) \\, d \\lambda } \\cdot \\frac { 1 } { \\sigma _ { i } ^ { 2 } } ,</formula>\n",
      "<text><loc_261><loc_440><loc_459><loc_454>with T$_{est}$ representing an estimated effective temperature at the orbital phase of interest. When computing</text>\n",
      "</doctag><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(doc_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82158cd0",
   "metadata": {},
   "source": [
    "Render the output in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1b3277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "while the kernel weights are structured as ( N$\\_{slice}$ , N$\\_{time}$ ). This precomputation significantly accelerates our calculations, which is essential since the longitudinal slices are at least partially degenerate with one another. Consequently, the fits require more steps and walkers to ensure proper convergence.\n",
       "\n",
       "To address this, we follow a similar approach to our sinusoidal fits using emcee , but we increase the total number of steps to 100,000 and use 100 walkers. Na¨ıvely, the fit would include 2 N$\\_{slice}$ + 1 parameters: N$\\_{slice}$ for the albedo values, N$\\_{slice}$ for the emission parameters, and one additional scatter parameter, σ . However, since night-side slices do not contribute to the reflected light component, we exclude these albedo values from the fit. In any case, our choice of 100 walkers ensures a sufficient number of walkers per free parameter. Following Coulombe et al. (2025) we set an upper prior limit of 3 / 2 on all albedo slices as a fully Lambertian sphere ( A$\\_{i}$ = 1 ) corresponds to a geometric albedo of A$\\_{g}$ = 2 / 3. For thermal emission we impose a uniform prior between 0 and 500 ppm for each slice.\n",
       "\n",
       "We choose to fit our detrended lightcurves considering 4, 6 and 8 longitudinal slices ( N$\\_{slice}$ = 4 , 6 , 8). However, we show the results of the simplest 4 slice model. As in our previous fits, we conduct an initial run with 25,000 steps (25% of the total run) and use the maximumprobability parameters from this preliminary fit as the starting positions for the final 75,000-step run. We then discard the first 60% of the final run as burn-in.\n",
       "\n",
       "## 2.5. Planetary Effective Temperature\n",
       "\n",
       "Phase curves are the only way to probe thermal emission from the day and nightside of an exoplanet and hence determine its global energy budget (Partier &amp; Crossfield 2018). The wavelength range of NIRISS/SOSS covers a large portion of the emitted flux of WASP-121 b ( ∼ 50-83%; see Figure 2), enabling a precise and robust constraint of the planet's energy budget.\n",
       "\n",
       "We convert the fitted F$\\_{p}$ / F$\\_{∗}$ emission spectra to brightness temperature by wavelength,\n",
       "\n",
       "$$T _ { b r i g h t } = \\frac { h c } { k \\lambda } \\cdot \\left [ \\ln \\left ( \\frac { 2 b c ^ { 2 } } { \\lambda ^ { 5 } B _ { \\lambda , p l a n e t } } + 1 \\right ) \\right ] ^ { - 1 } ,$$\n",
       "\n",
       "where the planet's thermal emission is\n",
       "\n",
       "$$B _ { \\lambda , \\text {planet} } = \\frac { F _ { p } / F _ { * } } { ( R _ { p } / R _ { * } ) ^ { 2 } } \\cdot B _ { \\lambda , \\text {star} } \\, .$$\n",
       "\n",
       "There are many ways of converting brightness temperatures to effective temperature, including the ErrorWeighted Mean (EWM), Power-Weighted mean (PWM) and with a Gaussian Process (Schwartz &amp; Cowan 2015;\n",
       "\n",
       "Figure 2. Estimated captured flux of the planet assuming the planet radiates as a blackbody. The captured flux is calculated as the ratio of the integrated blackbody emission within the instrument's band pass to the total emission over all wavelengths, i.e., γ = ∫ λ$\\_{max}$ λ$\\_{min}$ B ( λ, T ) dλ/ ∫ ∞ 0 B ( λ, T ) dλ . The captured flux fraction is shown for NIRISS SOSS [0.6-2.85 µ m] (red line); Hubble WFC3 [1.12-1.64 µ m] (dashed green line); NIRSpec G395H [2.7-5.15 µ m] (dash dotted blue line). The red-shaded region shows the temperature range on WASP-121 b based on our T$\\_{eff}$ estimates. Red dashed lines indicate the boundaries of the planet's temperature range within the NIRISS SOSS captured flux fraction. From this we estimate that these observations capture between 55% and 82% of the planet's bolometric flux, depending on orbital phase. Using the minimum temperature from the NAMELESS fit, this estimate decreases to 50%. In either case, the wavelength coverage of NIRISS exceeds that of any other instrument.\n",
       "\n",
       "line chart\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Pass et al. 2019). In this work, we elect to compute our effective temperature estimates with a novel method that is essentially a combination of the PWM and EWM. We create the effective temperature by using a simple Monte Carlo process. First, we perturb our F$\\_{p}$ / F$\\_{s}$ emission spectra at each point in the orbit by a Gaussian based on the measurement uncertainty. Our new emission spectrum is then used to create an estimate of the brightness temperature spectrum. This process is repeated at each orbital phase. We then estimate the effective temperature, T$\\_{eff}$ for a given orbital phase as\n",
       "\n",
       "$$T _ { \\text {eff} } = \\frac { \\sum _ { i = 1 } ^ { N } w _ { i } T _ { \\text {bright,} } , } { \\sum _ { i = 1 } ^ { N } w _ { i } } ,$$\n",
       "\n",
       "where w$\\_{i}$ is the weight for the i -th wavelength given by the fraction of the planet's bolometric flux that falls within that wavelength bin scaled by the inverse variance of the measurement,\n",
       "\n",
       "$$w _ { i } = \\frac { \\int _ { \\lambda _ { i } } ^ { \\lambda _ { i } + 1 } B ( \\lambda _ { i } , T _ { \\text {est} } ) \\, d \\lambda } { \\int _ { 0 } ^ { \\infty } B ( \\lambda _ { i } , T _ { \\text {est} } ) \\, d \\lambda } \\cdot \\frac { 1 } { \\sigma _ { i } ^ { 2 } } ,$$\n",
       "\n",
       "with T$\\_{est}$ representing an estimated effective temperature at the orbital phase of interest. When computing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from docling_core.types.doc.document import DoclingDocument, DocTagsDocument\n",
    "\n",
    "\n",
    "doctag_document = DocTagsDocument.from_doctags_and_image_pairs(\n",
    "    doctags=[doc_tags], images=[image]\n",
    ")\n",
    "docling_document = DoclingDocument.load_from_doctags(\n",
    "    doctag_document=doctag_document, document_name=\"Document\"\n",
    ")\n",
    "extracted_text_markdown = docling_document.export_to_markdown()\n",
    "display(Markdown(extracted_text_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27591d54",
   "metadata": {},
   "source": [
    "Save the extracted text to a file so that we can review it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d49d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/extracted_text/granite_docling_output.txt\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(extracted_text_markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c89d9",
   "metadata": {},
   "source": [
    "### Using llama.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dc9cc",
   "metadata": {},
   "source": [
    "For some reason, using transformers is very slow, even with a GPU. So, let's try using `llama.cpp` instead. First, download the model in `GGUF` format from [ggml-org repository](https://huggingface.co/ggml-org/granite-docling-258M-GGUF/tree/main). Choose which quantization you want to use. This model is small, so I went with half precision (f16).\n",
    "\n",
    "Download two files, one for the language model, and the other for the vision encoder (mmproj). For the 16-bit model, the files are:\n",
    "\n",
    "- `granite-docling-258M-f16.gguf`\n",
    "- `mmproj-granite-docling-258M-f16.gguf`\n",
    "\n",
    "After that serve the model using [llama-server](https://github.com/ggml-org/llama.cpp/blob/master/tools/server/README.md):\n",
    "\n",
    "```bash\n",
    "llama-server \\\n",
    "  --model ~/.cache/llama.cpp/granite-docling-258M-f16.gguf \\\n",
    "  --mmproj ~/.cache/llama.cpp/mmproj-granite-docling-258M-f16.gguf \\\n",
    "  --n-gpu-layers 999 \\\n",
    "  --ctx-size 4096 \\\n",
    "  --port 36912\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230644b2",
   "metadata": {},
   "source": [
    "Here we define a function that takes an image path as input, encodes the image in base64 format, and returns a data URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0564a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "\n",
    "def encode_image_to_data_uri(image_path: str) -> str:\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = \"application/octet-stream\"\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    return f\"data:{mime_type};base64,{encoded_string}\"\n",
    "\n",
    "\n",
    "path_to_image = \"../images/test_ocr.png\"\n",
    "image_data_uri = encode_image_to_data_uri(path_to_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28084501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Don't forget to start the llama.cpp server!\n",
    "LLAMA_SERVER_URL = \"http://localhost:36912\"\n",
    "\n",
    "\n",
    "def extract_text_from_images(model_name: str, prompt: str, image_data_uri: str) -> str:\n",
    "    url = f\"{LLAMA_SERVER_URL}/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_uri}},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data = {\n",
    "        \"messages\": messages,\n",
    "        \"model\": model_name,\n",
    "        \"max_tokens\": 4096,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "\n",
    "        assistant_message = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return assistant_message.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "model_to_use = \"granite-docling-258M\"\n",
    "text_prompt = \"Convert this page to docling.\"\n",
    "\n",
    "doc_tags_llama_cpp = extract_text_from_images(model_to_use, text_prompt, image_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b893df",
   "metadata": {},
   "source": [
    "Ah, look at the speed difference! It took only 5 seconds to process the same image instead of 5 minutes. Let's see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de02759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E NERGY BUDGET OF WASP-121 b FROM JWST/NIRISS PHASE CURVE\n",
      "9\n",
      "while the kernel weights are structured as ( N$_{slice}$ , N$_{time}$ ). This precomputation significantly accelerates our calculations, which is essential since the longitudinal slices are at least partially degenerate with one another. Consequently, the fits require more steps and walkers to ensure proper convergence.\n",
      "To address this, we follow a similar approach to our sinusoidal fits using emcee , but we increase the total number of steps to 100,000 and use 100 walkers. Na¨¨vely, the fit would include 2 N$_{slice }$ + 1 parameters: N$_{slice}$ for the albedo values, N$_{slice}$ for the emission parameters, and one additional scatter parameter, σ . However, since night-side slices do not contribute to the reflected light component, we exclude these albedo values from the fit. In any case, our choice of 100 walkers ensures a sufficient number of walkers per free parameer. Following Coulombe et al. (2025) we set an upper prior limit of 3/2 on all albedo slices as a fully Lambertian sphere ( A$_{i}$ = 1) corresponds to a geometric albedo of A$_{g}$ = 2/3. For thermal emission we impose a uniform prior between 0 and 500 ppm for each slice.\n",
      "We choose to fit our detrended lightcurves considering 4, 6 and 8 longitudinal slices ( N$_{slice}$ = 4, 6, 8). However, we show the results of the simplest 4 slice model. As in our previous fits, we conduct an initial run with 25,000 steps (25% of the total run) and use the maximumprobability parameters from this preliminary fit as the starting positions for the final 75,000-step run. We then discard the first 60% of the final run as burn-in.\n",
      "2.5. Planetary Effective Temperature\n",
      "Phase curves are the only way to probe thermal emission from the day and nightside of an exoplanet and hence determine its global energy budget (Parrantier & Crossfield 2018). The wavelength range of NIRISS/SOSS covers a large portion of the emitted flux of WASP-121 b (~ 50-83%; see Figure 2), enabling a precise and robust constraint of the planet's energy budget.\n",
      "We convert the fitted F$_{p}$/F$_{∗}$ emission spectra to brightness temperature by wavelength,\n",
      "T _ { b r i g h t } = \\frac { b c } { k \\lambda } \\cdot \\left [ \\ln \\left ( \\frac { 2 b c ^ { 2 } } { \\lambda ^ { 5 } B _ { \\lambda , p l a n t e } } + 1 \\right ) \\right ] ^ { - 1 } ,\n",
      "where the planet's thermal emission is\n",
      "B _ { \\lambda , \\text {planet} } = \\frac { F _ { p } / F _ { * } } { ( R _ { p } / R _ { * } ) ^ { 2 } } \\cdot B _ { \\lambda , \\text {star} } \\, .\n",
      "There are many ways of converting brightness temperatures to effective temperature, including the ErrorWeighted Mean (EWM), Power-Weighted mean (PWM) and with a Gaussian Process (Schwartz & Cowan 2015;\n",
      "Figure 2. Estimated captured flux of the planet assuming the planet radiates as a blackbody. The captured flux is calculated as the ratio of the integrated blackbody emission within the instrument's band pass to the total emission over all wavelengths, i.e., γ = ∫ λ$_{min}$ λ$_{min}$ B ( λ , T ) dλ ∞ 0 B ( λ , T ) dλ. The captured flux fraction is shown for NIRISS SOSS [0.6-2.85 μ m] (red line); Hubble WFC3 [1.12-1.64 μ m] (dashed green line); NIRSpec G395H [2.7-5.15 μ m] (dash dotted blue line). The red-shaded region shows the temperature range on WASP-121 b based on T$_{effi}$ estimates. Red dashed lines indicate the boundaries of the planet's temperature range within the NIRISS SOSS captured flux fraction. From this we estimate that these observations capture between 55% and 82% of the planet's bolometric flux, depending on orbital phase. Using the minimum temperature from the NAMELESS fit, this estimate decreases to 50%. In either case, the wavelength coverage of NIRISS exceeds that of any other instrument.\n",
      "Pass et al. 2019). In this work, we elect to compute our effective temperature estimates with a novel method that is essentially a combination of the PWM and EWM. We create the effective temperature by using a simple Monte Carlo process. First, we perturb our F$_{p}$/F$_{s}$ emission spectra at each point in the orbit by a Gaussian based on the measurement uncertainty. Our new emission spectrum is then used to create an estimate of the brightness temperature spectrum. This process is repeated at each orbital phase. We then estimate the effective temperature, T$_{effi}$ for a given orbital phase as\n",
      "T _ { e f f } = \\frac { \\sum _ { i = 1 } ^ { N } w _ { i } T _ { b r i g h t , i } } { \\sum _ { i = 1 } ^ { N } w _ { i } } ,\n",
      "where w$_{i}$ is the weight for the i -th wavelength given by the fraction of the planet's bolometric flux that falls within that wavelength bin scaled by the inverse variance of the measurement,\n",
      "w _ { i } = \\frac { \\int _ { \\lambda _ { i } ^ { + 1 } } ^ { \\lambda _ { i } } B ( \\lambda _ { i } , T _ { e s t } ) \\, d \\lambda } { \\int _ { 0 } ^ { \\infty } B ( \\lambda _ { i } , T _ { e s t } ) \\, d \\lambda } \\cdot \\frac { 1 } { \\sigma _ { i } ^ { 2 } } ,\n",
      "with T$_{est}$ representing an estimated effective temperature at the orbital phase of interest. When computing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_inner_text(text_with_tags: str) -> str:\n",
    "    return re.sub(r\"<.*?>\", \"\", text_with_tags, flags=re.DOTALL).strip()\n",
    "\n",
    "\n",
    "extracted_text_llama_cpp = \"\"\n",
    "for line in doc_tags_llama_cpp.splitlines():\n",
    "    extracted_text_llama_cpp += extract_inner_text(text_with_tags=line) + \"\\n\"\n",
    "\n",
    "print(extracted_text_llama_cpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4dada",
   "metadata": {},
   "source": [
    "Save the extracted text to a file so that we can review it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d810aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/extracted_text/granite_docling_output.txt\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(extracted_text_llama_cpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc0bbc",
   "metadata": {},
   "source": [
    "Now, let's use the same model on the scanned PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a79bcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC REVISED EDITIONVS DECEMBER 2024\n",
      "ROG STRIX\n",
      "GAMING NOTEBOOK PC\n",
      "MORE INFO\n",
      "\n",
      "Gaming\n",
      "RCER CERRE RIE ERE RE\n",
      "ASUS PROVIDES THIS MANUAL AS IS WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED WARRANTIES OR CONDITIONS OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, IN NO EVENT SHALL ASUS, ITS DIRECTORS, OFFICERS, EMPLOYEES OR AGENTS BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES (INCLUDING DAMAGES FOR LOSS OF PROFITS, LOSS OF BUSINESS, LOSS OF USE OR DATA, INTERRUPTION OF BUSINESS AND THE LIKE), EVEN IF ASUS HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES ARISING FROM ANY DEFECT OR ERROR IN THIS MANUAL OR PRODUCT.\n",
      "Products and corporate names appearing in this manual may or may not be registered trademarks or copyrights of their respective companies, and are used only for identification or explanation and to the owners' benefit, without intent to infringe.\n",
      "SPECIFICATIONS AND INFORMATION CONTAINED IN THIS MANUAL ARE FURNISHED FOR INFORMATIONAL USE ONLY, AND ARE SUBJECT TO CHANGE AT ANY TIME WITHOUT NOTICE, AND SHOULD NOT BE CONSTRUED AS A COMMITMENT BY ASUS, ASUS ASSUMES NO RESPONSIBILITY OR LIABILITY FOR ANY ERRORS OR INACCURACIES THAT MAY APPEAR IN THIS MANUAL, INCLUDING THE PRODUCTS AND SOFTWARE DESCRIBED IN IT.\n",
      "Copyright © 2024 ASUSTek COMPUTER INC. All Rights Reserved.\n",
      "LIMITATION OF LIABILITY\n",
      "Circumstances may arise where because of a default on ASUS' part or other liability, you are entitled to recover damages from ASUS. In each such instance, regardless of the basis on which you are entitled to claim damages from ASUS, ASUS is liable for no more than damages for bodily injury (including death) and damage to real property and tangible personal property; or any other actual and direct damages resulted from omission or failure of performing legal duties under this Warranty Statement, up to the listed contract price of each product.\n",
      "ASUS will only be responsible for or indemnify you for loss, damages or claims based in contract, tort or infringement under this Warranty Statement.\n",
      "This limit also applies to ASUS' suppliers and its reseller. It is the maximum for which ASUS, its suppliers, and your reseller are collectively responsible.\n",
      "UNDER NO CIRCUMSTANCES IS ASUS LIABLE FOR ANY OF THE FOLLOWING: (1) THIRD-PARTY CLAIMS AGAINST YOUR DAMAGES: (2) LOSS OF OR DAMAGE TO, YOUR RECORDS OR DATA; OR (3) SPECIAL, INCIDENTAL, OR INDIRECT DAMAGES OR FOR ANY ECONOMIC CONSEQUENTIAL DAMAGES (INCLUDING LOST PROFITS OR SAVINGS), EVEN IF ASUS, ITS SUPPLIERS OR YOUR RESELLER IS INFORMED OF THEIR POSSIBILITY.\n",
      "SERVICE AND SUPPORT\n",
      "Visit our multi-language website at https://www.asus.com/support/\n",
      "MyASUS offers a variety of support features including troubleshooting, products performance optimization, ASUS software integration, and helps you to organize personal desktop and increase storage space. For more details, please visit https://www.asus.com/support/FAQ/1038301.\n",
      "2\n",
      "3\n",
      "Chapter 3: Working with Windows\n",
      "Starting for the first time 46 Start menu 47 Windows apps 49 Working with Windows apps 50 Customizing Windows apps 51 Task view 52 Widgets 53 Snap feature 55 Snap hotspots 56 Action Center 57 GameVisual 59 Setting the OLED display 61 Setting the Dark Mode 62 Turning off the display when not in use 63 Adjusting display brightness 64 Auto-hide the taskbar 65 Setting the Dark Mode in Microsoft Office 69 Other keyboard shortcuts 70 Connecting to wireless networks 71 Wi-Fi 72 Bluetooth 73 Airplane mode 74 Connecting to wired networks 75 Turning your Notebook PC off 76 Putting your Notebook PC to sleep 78 Putting your Notebook PC into the lowest power mode 79\n",
      "4\n",
      "Using POST to access BIOS and Troubleshoot............................................................. 82\n",
      "BIOS............................................................. 82\n",
      "Accessing BIOS.............................................................. 82\n",
      "Recovering your system................................................................. 83\n",
      "Performing a recovery option................................................. 84\n",
      "Tips and FAQs............................................................................. 88\n",
      "\n",
      "5\n",
      "6\n",
      "This manual provides information about the hardware and software features of your Notebook PC, organized through the following chapters:\n",
      "Chapter 1: Hardware Setup\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "7\n",
      "Conventions used in this manual\n",
      "To highlight key information in this manual, some text are presented as follows:\n",
      "IMPORTANT! This message contains vital information that must be followed to complete a task.\n",
      "NOTE: This message contains additional information and tips that can help complete tasks.\n",
      "WARNING! This message contains important information that must be followed to keep safe while performing tasks and prevent damage to your Notebook PC's data and components.\n",
      "The icons below indicate the devices you can use for completing a series of tasks or procedures on your Notebook PC\n",
      "\n",
      "\n",
      "= Use the touchpad.\n",
      "= Use the keyboard.\n",
      "Bold\n",
      "Italic\n",
      "= This indicates sections that you can refer to in this manual.\n",
      "8\n",
      "This Notebook PC should only be used in environments with ambient temperatures between 5°C (41°F) and 35°C (95°F).\n",
      "Refer to the rating label on the bottom of your Notebook PC and ensure that your power adapter complies with this rating.\n",
      "Your Notebook PC can get warm to hot while in use or while charging the battery pack. Do not leave your Notebook PC on your lap or near any part of your body to prevent injury from heat. When working on your Notebook PC, do not place it on surfaces that can block the vents.\n",
      "Do not use damaged power cords, accessories, and other peripherals with your Notebook PC.\n",
      "While powered on, ensure that you do not carry or cover your Notebook PC with any materials that can reduce air circulation.\n",
      "Do not place your Notebook PC on uneven or unstable work surfaces.\n",
      "You can send your Notebook PC through x-ray machines (used on items placed on conveyor belts), but do not expose them to magnetic detectors and wand's.\n",
      "Contact your airline provider to learn about related in-flight services that can be used and restrictions that must be followed when using your Notebook PC in-flight.\n",
      "9\n",
      "Caring for your Notebook PC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "Do not use strong solvents such as alcohol, thinners, benzene, or other chemicals on or near your Notebook PC.\n",
      "Do not place objects on top of your Notebook PC.\n",
      "Do not expose your Notebook PC to strong magnetic or electrical fields.\n",
      "Do not use or expose your Notebook PC near liquids, rain, or moisture.\n",
      "Do not expose your Notebook PC to dusty environments.\n",
      "Do not use your Notebook PC near gas leaks.\n",
      "Do not place active electronic devices close to your Notebook PC to avoid electromagnetic wave interference to the display panel.\n",
      "Do not use this Notebook PC for cryptocurrency mining (consuming a vast amount of electricity and time to gain convertible virtual currency) and/or related activities.\n",
      "Do not throw your Notebook PC in municipal waste. This product has been designed to enable proper reuse of parts and recycling. The symbol of the crossed out wheeled bin indicates that the product (electrical, electronic equipment and mercury- containing button cell battery) should not be placed in municipal waste. Check local regulations for disposal of electronic products.\n",
      "Do not throw the battery in municipal waste. The symbol of the crossed out wheeled bin indicates that the battery should not be placed in municipal waste.\n",
      "11\n",
      "12\n",
      "· If you are not using your device for a long period of time, ensure to charge the battery power to 50% then power off your device and disconnect the AC power adapter. Recharge the battery power to 50% every three months to avoid over-discharging and prevent damage to the battery.\n",
      "· Avoid charging the battery at high voltage for a prolonged period of time to extend the battery life. If you are constantly using AC power for your device, ensure to discharge the battery power to 50% at least once every two weeks. You can also adjust the settings from Battery Health Charging in MyASUS to help extend the battery life.\n",
      "· It is recommended to store your battery at temperatures between 5°C (41°F) and 35°C (95°F) with the battery power at 50%. You can also adjust the settings from Battery Health Charging in MyASUS to help extend the battery life.\n",
      "· Do not leave your battery in damp environments. Exposure to damp environments may increase the battery over-discharging rate. Low temperature environment may damage the chemicals inside the battery while high temperature or overheating may result in a risk of explosion.\n",
      "· Do not place your device or battery pack near radiators, fireplaces, furnaces, heaters, or any sources of heat with temperature exceeding 60°C (140°F). High temperature surrounding environment may result in an explosion or leakage that may cause fire.\n",
      "\n",
      "13\n",
      "15\n",
      "Copyright © 2016 - 2019, The University of Manchester. All rights reserved.\n",
      "Front View\n",
      "16\n",
      "17\n",
      "5 Status indicators\n",
      "The status indicators help identify the current hardware status of your Notebook PC.\n",
      "\n",
      "\n",
      "Power indicator\n",
      "The power indicator lights up when the Notebook PC is turned on and blinks slowly when the Notebook PC is in sleep mode.\n",
      "\n",
      "Two-color battery charge indicator\n",
      "The two-color LED provides a visual indication of the battery's charge status. Refer to the following table for details:\n",
      "18\n",
      "\n",
      "6 Capital lock indicator\n",
      "7\n",
      "8\n",
      "8\n",
      "\n",
      "8\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "extracted_text_from_all_pages = \"\"\n",
    "model_to_use = \"granite-docling-258M\"\n",
    "text_prompt = \"Convert this page to docling.\"\n",
    "\n",
    "pdf_path = \"../data/documents/rog_strix_gaming_notebook_pc_scanned_file.pdf\"\n",
    "pdf_document = pymupdf.open(pdf_path)\n",
    "\n",
    "for page in tqdm(pdf_document, total=pdf_document.page_count):  # type: ignore\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    image_bytes = pix.tobytes(\"png\")\n",
    "    encoded_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    data_uri = f\"data:image/png;base64,{encoded_string}\"\n",
    "\n",
    "    extracted_text_from_page_with_tags = extract_text_from_images(\n",
    "        model_name=model_to_use, prompt=text_prompt, image_data_uri=data_uri\n",
    "    )\n",
    "    extracted_text_from_page = extract_inner_text(\n",
    "        text_with_tags=extracted_text_from_page_with_tags\n",
    "    )\n",
    "    extracted_text_from_all_pages += extracted_text_from_page + \"\\n\"\n",
    "\n",
    "print(extracted_text_from_all_pages.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a867d6",
   "metadata": {},
   "source": [
    "Save the extracted text to a file so that we can review it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ed854f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/extracted_text/granite_docling_output.txt\"\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(extracted_text_from_all_pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_embedding_models_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
