{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f8ea42",
   "metadata": {},
   "source": [
    "# Translate text to other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678caa",
   "metadata": {},
   "source": [
    "You will take the text chunks and questions that you have created in the previous notebook and translate them to other languages using OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f4c43",
   "metadata": {},
   "source": [
    "Define the target language you want to translate to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def5f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language = \"arabic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1b338",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef72fe0",
   "metadata": {},
   "source": [
    "### Create the system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e83cc",
   "metadata": {},
   "source": [
    "Create a system prompt to teach the LLM how to perform the translation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc1914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "## Task description\n",
    "\n",
    "You are a world-class translator. Your task is to translate a given text into a specified target language. Don't do a literal word-for-word translation; instead, ensure that the translated text captures the original meaning, tone, and context.\n",
    "\n",
    "### Important instructions:\n",
    "\n",
    "- Don't add or remove any information from the original text.\n",
    "- Maintain the original tone and style of the text.\n",
    "- Return only the translated text without any additional commentary or explanations.\n",
    "\n",
    "Here is the text, please translate it into {target_language}:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646105b",
   "metadata": {},
   "source": [
    "### Create a Pydantic object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247a831",
   "metadata": {},
   "source": [
    "We use a Pydantic object to define the structure of the output we want from the LLM. This will force the LLM to return the output in a structured format that we can easily parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a9a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class TranslatedText(BaseModel):\n",
    "    text: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439f50c",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39831623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 42 text chunks.\n",
      "Loaded 494 questions.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "prefix = \"imad_saddik_end_of_studies_internship_report_chunks\"\n",
    "text_chunk_file_path = f\"../data/chunks/{prefix}.json\"\n",
    "questions_file_path = f\"../data/question_answer_pairs/{prefix}_qa_pairs.json\"\n",
    "\n",
    "with open(text_chunk_file_path, \"r\") as f:\n",
    "    text_chunks = json.load(f)\n",
    "\n",
    "with open(questions_file_path, \"r\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(text_chunks)} text chunks.\")\n",
    "print(f\"Loaded {len(questions)} questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f2357",
   "metadata": {},
   "source": [
    "### Use OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a764623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b292a",
   "metadata": {},
   "source": [
    "Prepare to save the translated chunks and questions in the same direcotories as before but with a suffix indicating the target language. \n",
    "\n",
    "For example, if the target language is Arabic, the files will be saved as `chunks_arabic.json` and `chunks_qa_pairs_arabic.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3148925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [16:16<00:00, 23.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import APIConnectionError, RateLimitError, InternalServerError\n",
    "\n",
    "MAX_RETRIES = 5\n",
    "INITIAL_DELAY_SECONDS = 2\n",
    "\n",
    "for chunk in tqdm(text_chunks, total=len(text_chunks)):\n",
    "    text = chunk[\"text_chunk\"]\n",
    "\n",
    "    delay = INITIAL_DELAY_SECONDS\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=\"gpt-4.1\",\n",
    "                input=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text},\n",
    "                ],\n",
    "                text_format=TranslatedText,\n",
    "            )\n",
    "\n",
    "            translated_text: TranslatedText = response.output_parsed  # type: ignore\n",
    "            chunk[\"text_chunk\"] = translated_text.text\n",
    "            break\n",
    "\n",
    "        except (APIConnectionError, RateLimitError, InternalServerError) as e:\n",
    "            if attempt == MAX_RETRIES - 1:\n",
    "                print(f\"FINAL ATTEMPT FAILED for a chunk. Error: {e}\")\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"Model overloaded (503). Retrying in {delay} seconds... (Attempt {attempt + 1}/{MAX_RETRIES})\"\n",
    "            )\n",
    "\n",
    "            time.sleep(delay)\n",
    "            delay *= 2\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred with a chunk: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e003599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [12:20<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "for question_object in tqdm(questions, total=len(questions)):\n",
    "    question_text = question_object[\"question\"]\n",
    "\n",
    "    delay = INITIAL_DELAY_SECONDS\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.responses.parse(\n",
    "                model=\"gpt-4.1\",\n",
    "                input=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question_text},\n",
    "                ],\n",
    "                text_format=TranslatedText,\n",
    "            )\n",
    "\n",
    "            translated_text: TranslatedText = response.output_parsed  # type: ignore\n",
    "            question_object[\"question\"] = translated_text.text\n",
    "            break\n",
    "\n",
    "        except (APIConnectionError, RateLimitError, InternalServerError) as e:\n",
    "            if attempt == MAX_RETRIES - 1:\n",
    "                print(f\"FINAL ATTEMPT FAILED for a chunk. Error: {e}\")\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"Model overloaded (503). Retrying in {delay} seconds... (Attempt {attempt + 1}/{MAX_RETRIES})\"\n",
    "            )\n",
    "\n",
    "            time.sleep(delay)\n",
    "            delay *= 2\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred with a chunk: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02aec2",
   "metadata": {},
   "source": [
    "### Save the translated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5910c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text_chunk_file_path = f\"../data/chunks/{prefix}_{target_language}.json\"\n",
    "translated_questions_file_path = (\n",
    "    f\"../data/question_answer_pairs/{prefix}_qa_pairs_{target_language}.json\"\n",
    ")\n",
    "\n",
    "with open(translated_text_chunk_file_path, \"w\") as f:\n",
    "    json.dump(text_chunks, f, indent=2)\n",
    "\n",
    "with open(translated_questions_file_path, \"w\") as f:\n",
    "    json.dump(questions, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_embedding_models_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
